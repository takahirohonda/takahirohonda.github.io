"use strict";(self.webpackChunkmydatahack_blog_site=self.webpackChunkmydatahack_blog_site||[]).push([[2845],{30709:(e,t,i)=>{i.r(t),i.d(t,{assets:()=>c,contentTitle:()=>s,default:()=>m,frontMatter:()=>a,metadata:()=>r,toc:()=>d});var n=i(74848),o=i(28453);const a={sidebar_position:8},s="Compatibility with AWS Redshift",r={id:"ETL/informatica/compatibility-with-redshit",title:"Compatibility with AWS Redshift",description:"ETL in Redshift demands a specialised connector that optimises insert and upsert operations. Generic JDBC or ODBC ones are too slow and inefficient. When it comes to bulk loading, Amazon recommends to load data into Redshift via S3 by using a copy command (see here). The traditional insert statement is much less efficient than the magical copy command.",source:"@site/docs/ETL/informatica/8.compatibility-with-redshit.md",sourceDirName:"ETL/informatica",slug:"/ETL/informatica/compatibility-with-redshit",permalink:"/docs/ETL/informatica/compatibility-with-redshit",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:8,frontMatter:{sidebar_position:8},sidebar:"tutorialSidebar",previous:{title:"How To Resolve Unknown Host Name For Secure Agent In Linux",permalink:"/docs/ETL/informatica/unknown-host-error"},next:{title:"Incremental Load With Data Synchronization Task",permalink:"/docs/ETL/informatica/incremental-data-load"}},c={},d=[];function h(e){const t={h1:"h1",img:"img",p:"p",...(0,o.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(t.h1,{id:"compatibility-with-aws-redshift",children:"Compatibility with AWS Redshift"}),"\n",(0,n.jsx)(t.p,{children:"ETL in Redshift demands a specialised connector that optimises insert and upsert operations. Generic JDBC or ODBC ones are too slow and inefficient. When it comes to bulk loading, Amazon recommends to load data into Redshift via S3 by using a copy command (see here). The traditional insert statement is much less efficient than the magical copy command."}),"\n",(0,n.jsx)(t.p,{children:"Redshift does not support a single merge or upsert statement. Upserting records in Redshift involves in creating a staging table and loading the data into it first (updating and inserting). From the staging table, we either (1) delete the old record and re-insert the entire updated one (merge by replacing existing rows) or (2) perform update and insert from the staging table (merge by specifying a column list)."}),"\n",(0,n.jsx)(t.p,{children:"Informatica Redshift connector can take care of the logistics for you. It can optimise the load for the cluster size as well as manage the complex data staging for insert and update operations behind the scene. When you specify to insert the record, it first upload the data into S3 and use copy command for the optimal bulk loading performance. For upsert, it will create a staging table and execute the merge operation in the background. I have not yet seen any performance issue in executing incremental load in both Data Synchronization and Mapping tasks. When it comes to loading dimensional tables, it can preserve the dimension key whenever update happens on the record without compromise too much on the loading speed."}),"\n",(0,n.jsx)(t.p,{children:"Configuring the connector is very similar to other database connectors."}),"\n",(0,n.jsx)(t.p,{children:"Firstly, add the connection name and choose type as AmazoneRedshift (Informatica Cloud)."}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.img,{alt:"img",src:i(15141).A+"",width:"1468",height:"238"})}),"\n",(0,n.jsx)(t.p,{children:"For the connection properties, you need to add AWS Access Key ID and AWS Access Key as it uses S3 for loading data. There is no place to specify the bucket name. The bucket needs to be specified in Source or Target stage every time you use the connection."}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.img,{alt:"img",src:i(76216).A+"",width:"1467",height:"740"})}),"\n",(0,n.jsx)(t.p,{children:"Let us know about your experience with the connector."}),"\n",(0,n.jsx)(t.p,{children:"(2017-08-13)"})]})}function m(e={}){const{wrapper:t}={...(0,o.R)(),...e.components};return t?(0,n.jsx)(t,{...e,children:(0,n.jsx)(h,{...e})}):h(e)}},15141:(e,t,i)=>{i.d(t,{A:()=>n});const n=i.p+"assets/images/img-1-1efbefb405aa08f609f9c08be2baff75.webp"},76216:(e,t,i)=>{i.d(t,{A:()=>n});const n=i.p+"assets/images/img-2-832d9c5c9d53a81aa785639a893e3790.webp"},28453:(e,t,i)=>{i.d(t,{R:()=>s,x:()=>r});var n=i(96540);const o={},a=n.createContext(o);function s(e){const t=n.useContext(a);return n.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function r(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:s(e.components),n.createElement(a.Provider,{value:t},e.children)}}}]);