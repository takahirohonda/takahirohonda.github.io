"use strict";(self.webpackChunkmydatahack_blog_site=self.webpackChunkmydatahack_blog_site||[]).push([[9953],{37227:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>i,default:()=>m,frontMatter:()=>a,metadata:()=>o,toc:()=>l});var s=t(74848),r=t(28453);const a={sidebar_position:28},i="How To Get Data From Google Analytics With Python",o={id:"data-ingestion/ga-py",title:"How To Get Data From Google Analytics With Python",description:"When you ingest data from Google Analytics, you need to create a series of reports based on GA dimensions and metrics. The granularity is determined by dimensions you add in the report. The most important thing is to understand business requirements before start ingesting data. Good requirement analysis will enable you to drill up and down metrics at the right granularity and slice them with the dimensions that are critical to the business.",source:"@site/docs/data-ingestion/28.ga-py.md",sourceDirName:"data-ingestion",slug:"/data-ingestion/ga-py",permalink:"/mydatahack-old-blog/docs/data-ingestion/ga-py",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:28,frontMatter:{sidebar_position:28},sidebar:"tutorialSidebar",previous:{title:"Data Engineering in S3 and Redshift with Python",permalink:"/mydatahack-old-blog/docs/data-ingestion/s3-redshift-py"},next:{title:"How To Get Facebook Data With Python",permalink:"/mydatahack-old-blog/docs/data-ingestion/facebook-py"}},d={},l=[];function c(e){const n={a:"a",code:"code",h1:"h1",p:"p",pre:"pre",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.h1,{id:"how-to-get-data-from-google-analytics-with-python",children:"How To Get Data From Google Analytics With Python"}),"\n",(0,s.jsx)(n.p,{children:"When you ingest data from Google Analytics, you need to create a series of reports based on GA dimensions and metrics. The granularity is determined by dimensions you add in the report. The most important thing is to understand business requirements before start ingesting data. Good requirement analysis will enable you to drill up and down metrics at the right granularity and slice them with the dimensions that are critical to the business."}),"\n",(0,s.jsx)(n.p,{children:"Google Analytics (for free version) only allows us to have up to 7 dimensions and 10 metrics in a single report. You also need to note that not all dimensions and metrics can be queried together. In my example, I created reports over the key metrics and grouped dimensions according to the GA Dimensions & Metrics Explorer . For example, I created the ga_dim_geo table, which have the dimensions grouped under Geo Network. In my code, you can see how I grouped the same metrics against different dimension groups (like geo location, traffic source, device, channels and so on). GA has a really neat query tool (Query Explorer) where you can create ad hoc reports."}),"\n",(0,s.jsx)(n.p,{children:"The python script uses the Core Reporting API v3.0 and OAuth2.0. The details on how to obtain API keys and the example scripts can be found here."}),"\n",(0,s.jsx)(n.p,{children:"The report comes in the JSON format. Many databases allow you to insert JSON file to a table. You can also fetch the json file with an ETL tool and do the conversion. In this example, the script converts JSON to CSV."}),"\n",(0,s.jsxs)(n.p,{children:["There is also an example code in Java to get data from GA (a href=\u201d",(0,s.jsx)(n.a,{href:"https://www.mydatahack.com/how-to-get-data-from-google-analytics-with-java/%E2%80%9D",children:"https://www.mydatahack.com/how-to-get-data-from-google-analytics-with-java/\u201d"})," target=\u201d_blank\u201d>here."]}),"\n",(0,s.jsx)(n.p,{children:"Key Points"}),"\n",(0,s.jsx)(n.p,{children:"The maximum number of records you can get from this API is 10000. When you are trying to do a historical load, you will easily exceed the limit. I am using the start_index attribute for to iterate the API call until we get all the records."}),"\n",(0,s.jsx)(n.p,{children:"You can easily add a report in the script by adding report_name, dimensions and metrics in the main method. In this design, each report becomes a table."}),"\n",(0,s.jsx)(n.p,{children:"Credentials and file paths need to be in the arguments when you call the script as below:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"python script.py <key file location e.g. /tmp/key/key.p12> <service-email>\n<json_path e.g. /tmp/gadata/> <start-date e.g. 2017-11-01> <end-date e.g. 2017-11-02>\n<csv_path e.g. /tmp/gadata/>\n"})}),"\n",(0,s.jsx)(n.p,{children:"Here comes the code! Have fun!"}),"\n",(0,s.jsx)(n.p,{children:"Code"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"import json\nfrom apiclient.discovery import build\nfrom oauth2client.service_account import ServiceAccountCredentials\nimport httplib2\nfrom oauth2client import client\nfrom oauth2client import file\nfrom oauth2client import tools\n\nimport sys\n'''\nreloading sys for utf8 encoding is for Python 2.7\nThis line should be removed for Python 3\nIn Python 3, we need to specify encoding when open a file\nf = open(\"file.csv\", encoding='utf-8')\n'''\nreload(sys)\nsys.setdefaultencoding('utf8')\n\n# (1) Get Credentials and File Paths from Argument\nkey_file = sys.argv[1]\nservice_email = sys.argv[2]\njson_path = sys.argv[3]\nstart_date = sys.argv[4]\nend_date = sys.argv[5]\ncsv_path = sys.argv[6]\n\nscope=['https://www.googleapis.com/auth/analytics.readonly']\napi_name = 'analytics'\napi_version = 'v3'\n\n# (2) Create Credentials and build the Service Object\ndef get_service(key_file, service_email):\n    credentials = ServiceAccountCredentials.from_p12_keyfile(\\\n        service_email, key_file, scopes=scope)\n    http = credentials.authorize(httplib2.Http())\n    # Build the service object.\n    service = build(api_name, api_version, http=http)\n    return service\n\n# (3) Use the Analytics service object to get the first profile id\ndef get_first_profile_id(service):\n    # Get a list of all Google Analytics accounts for this user\n    accounts = service.management().accounts().list().execute()\n\n    if accounts.get('items'):\n        # Get the first Google Analytics account.\n        account = accounts.get('items')[0].get('id')\n\n        # Get a list of all the properties for the first account.\n        properties = service.management().webproperties().list(\n            accountId=account).execute()\n\n        if properties.get('items'):\n            # Get the first property id.\n            property = properties.get('items')[0].get('id')\n\n        # Get a list of all views (profiles) for the first property.\n        profiles = service.management().profiles().list(\n            accountId=account,\n            webPropertyId=property).execute()\n\n        if profiles.get('items'):\n            # return the first view (profile) id.\n            return profiles.get('items')[0].get('id')\n    return None\n\n# (4) Find the start-index for the next record\ndef find_next_index(url_string):\n    next_link = url_string\n    start_index_pos = next_link.find('start-index=')\n    end_pos = next_link.find('&', start_index_pos)\n    return int(next_link[start_index_pos + 12: end_pos])\n\n# (5) Convert Result to csv\ndef create_table(results_list, csv_path, header, report_name):\n    csv_file = csv_path + report_name + '.csv'\n    f = open(csv_file, \"w\")\n    f.write(header + '\\n')\n    for result in results_list:\n        result_row = result[\"rows\"]\n        for i in range(len(result_row)):\n            row_i = result_row[i]\n            row_string = ''\n            for j in range(len(row_i)):\n                row_string += row_i[j] + ','\n\n            f.write(row_string[:-1] + '\\n')\n    f.close()\n    print(\"{}.csv has been generated\".format(report_name))\n\n\n# (6) Get results, generate json file and return a list of results\ndef get_results(service, profile_id, start, end, metrics, dimensions, report_name, json_path):\n\n    counter = 0\n    start_index = 1\n    results_list = []\n\n    while True:\n        f_name = report_name + '_' + str(start_index) + '.json'\n        json_file_path = json_path + f_name\n\n        result = service.data().ga().get(\\\n            ids='ga:'+profile_id, start_date=start, end_date=end,\\\n            metrics=metrics, dimensions=dimensions, start_index=start_index,\\\n            max_results=10000).execute()\n        print(\"Total Record Number for the %s query result no.%s: %s\" \\\n        % (report_name, str(counter), len(result['rows'])))\n\n        results_list.append(result)\n        # Create Json Files\n        pretty = json.dumps(result, indent=1)\n        f = open(json_file_path, \"w\")\n        f.write(pretty)\n        f.close()\n        print(\"{} has been successfully generated.\".format(f_name))\n        try:\n            next_link = result[\"nextLink\"]\n            start_index = find_next_index(next_link)\n            counter += 1\n        except KeyError:\n            print(\"No more records to retrieve for {}\".format(f_name))\n            break\n    return results_list\n\n# (7) Create Header for csv file\ndef create_header(dimensions, metrics, report_name):\n    header = dimensions.replace('ga:', '') + ',' + metrics.replace('ga:', '')\n    header = header.replace(' ', '')\n    print(\"Table Name: {}\".format(report_name))\n    print(header)\n    return header\n\n# Main Method\ndef main():\n\n    # Authentication\n    service = get_service(key_file, service_email)\n    profile_id = get_first_profile_id(service)\n    print(\"Obtained Profile ID: \" + profile_id)\n\n    # Set up Reports\n    # (1) Metrics based on Geographical Dimensions\n    report_name = 'ga_dim_geo'\n    date_dim = ',ga:date,ga:hour'\n\n    dimensions = 'ga:country,\\\n                 ga:region,\\\n                 ga:city,\\\n                 ga:continent,\\\n                 ga:language' + date_dim\n\n    metrics = 'ga:users,\\\n                ga:newusers,\\\n                ga:sessions,\\\n                ga:bounces,\\\n                ga:sessionDuration,\\\n                ga:hits,\\\n                ga:pageviews'\n\n    header = create_header(dimensions, metrics, report_name)\n    results_list = get_results(service, profile_id, start_date, end_date, metrics, dimensions, report_name, json_path)\n    create_table(results_list, csv_path, header, report_name)\n\n    # (2) Metrics based on Traffic Source Dimensions\n    report_name = \"ga_dim_traffic_source\"\n    date_dim = ',ga:date,ga:hour'\n\n    dimensions = 'ga:source,\\\n                 ga:medium,\\\n                 ga:socialNetwork' + date_dim\n\n    metrics = 'ga:users,\\\n                ga:newusers,\\\n                ga:sessions,\\\n                ga:bounces,\\\n                ga:sessionDuration,\\\n                ga:hits,\\\n                ga:pageviews'\n\n    header = create_header(dimensions, metrics, report_name)\n    results_list = get_results(service, profile_id, start_date, end_date, metrics, dimensions, report_name, json_path)\n    create_table(results_list, csv_path, header, report_name)\n\n    # (3) Metrics based on Device Dimensions\n    report_name = \"ga_dim_device\"\n    date_dim = ',ga:date,ga:hour'\n\n    dimensions = 'ga:browser,\\\n                 ga:browserVersion,\\\n                 ga:screenResolution,\\\n                 ga:deviceCategory' + date_dim\n\n    metrics = 'ga:users,\\\n                ga:newusers,\\\n                ga:sessions,\\\n                ga:bounces,\\\n                ga:sessionDuration,\\\n                ga:hits,\\\n                ga:pageviews'\n\n    header = create_header(dimensions, metrics, report_name)\n    results_list = get_results(service, profile_id, start_date, end_date, metrics, dimensions, report_name, json_path)\n    create_table(results_list, csv_path, header, report_name)\n\n    # (4) Metrics based on Channel Grouping and Event Action\n    report_name = 'ga_dim_channel_event'\n\n    date_dim = ',ga:date,ga:hour'\n\n    dimensions = 'ga:channelGrouping,\\\n                 ga:eventAction' + date_dim\n\n    metrics = 'ga:uniqueEvents, \\\n                ga:users,\\\n                ga:newusers,\\\n                ga:sessions,\\\n                ga:bounces,\\\n                ga:sessionDuration,\\\n                ga:hits,\\\n                ga:pageviews'\n\n    header = create_header(dimensions, metrics, report_name)\n    results_list = get_results(service, profile_id, start_date, end_date, metrics, dimensions, report_name, json_path)\n    create_table(results_list, csv_path, header, report_name)\n\n    # (5) Goal Metrics by Channel Grouping\n    report_name ='ga_goal_dim_channel'\n\n    date_dim = ',ga:date,ga:hour'\n\n    dimensions = 'ga:channelGrouping' + date_dim\n\n    metrics = 'ga:goal15Completions,\\\n                ga:goal2Completions, \\\n                ga:goal7Completions, \\\n                ga:goal11Completions, \\\n                ga:goal12Completions, \\\n                ga:goal10Completions, \\\n                ga:goal19Completions, \\\n                ga:goal15Completions, \\\n                ga:transactions'\n\n    header = create_header(dimensions, metrics, report_name)\n    results_list = get_results(service, profile_id, start_date, end_date, metrics, dimensions, report_name, json_path)\n    create_table(results_list, csv_path, header, report_name)\n\n# Execute\nif __name__ == \"__main__\":\n    main()\n"})}),"\n",(0,s.jsx)(n.p,{children:"(2017-11-11)"})]})}function m(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},28453:(e,n,t)=>{t.d(n,{R:()=>i,x:()=>o});var s=t(96540);const r={},a=s.createContext(r);function i(e){const n=s.useContext(a);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:i(e.components),s.createElement(a.Provider,{value:n},e.children)}}}]);