"use strict";(self.webpackChunkmydatahack_blog_site=self.webpackChunkmydatahack_blog_site||[]).push([[8511],{37213:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>s,contentTitle:()=>l,default:()=>h,frontMatter:()=>o,metadata:()=>r,toc:()=>d});var a=t(74848),i=t(28453);const o={slug:"data-science/deep-learning/building-alexnet-with-keras",title:"Building AlexNet with Keras",tags:["Data Science","Deep Learning","AlexNet","Convolutional Neural Networks","Image Classification","Keras"]},l=void 0,r={permalink:"/data-science/data-science/deep-learning/building-alexnet-with-keras",source:"@site/data-science/deep-learning/2018-05-07-alexnet-keras.md",title:"Building AlexNet with Keras",description:"As the legend goes, the deep learning networks created by Alex Krizhevsky, Geoffrey Hinton and Ilya Sutskever (now largely know as AlexNet) blew everyone out of the water and won Image Classification Challenge (ILSVRC) in 2012. This heralded the new era of deep learning. AlexNet is the most influential modern deep learning networks in machine vision that use multiple convolutional and dense layers and distributed computing with GPU.",date:"2018-05-07T00:00:00.000Z",tags:[{label:"Data Science",permalink:"/data-science/tags/data-science"},{label:"Deep Learning",permalink:"/data-science/tags/deep-learning"},{label:"AlexNet",permalink:"/data-science/tags/alex-net"},{label:"Convolutional Neural Networks",permalink:"/data-science/tags/convolutional-neural-networks"},{label:"Image Classification",permalink:"/data-science/tags/image-classification"},{label:"Keras",permalink:"/data-science/tags/keras"}],readingTime:3.31,hasTruncateMarker:!0,authors:[],frontMatter:{slug:"data-science/deep-learning/building-alexnet-with-keras",title:"Building AlexNet with Keras",tags:["Data Science","Deep Learning","AlexNet","Convolutional Neural Networks","Image Classification","Keras"]},unlisted:!1,nextItem:{title:"Building AlexNet with TensorFlow and Running it with AWS SageMaker",permalink:"/data-science/data-science/deep-learning/building-alexnet-with-tensorflow-and-running-it-with-aws-sagemaker"}},s={authorsImageUrls:[]},d=[];function c(e){const n={code:"code",img:"img",p:"p",pre:"pre",strong:"strong",...(0,i.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.p,{children:"As the legend goes, the deep learning networks created by Alex Krizhevsky, Geoffrey Hinton and Ilya Sutskever (now largely know as AlexNet) blew everyone out of the water and won Image Classification Challenge (ILSVRC) in 2012. This heralded the new era of deep learning. AlexNet is the most influential modern deep learning networks in machine vision that use multiple convolutional and dense layers and distributed computing with GPU."}),"\n",(0,a.jsx)(n.p,{children:"Along with LeNet-5, AlexNet is one of the most important & influential neural network architectures that demonstrate the power of convolutional layers in machine vision. So, let\u2019s build AlexNet with Keras first, them move onto building it in ."}),"\n",(0,a.jsx)(n.p,{children:"Dataset"}),"\n",(0,a.jsx)(n.p,{children:"We are using OxfordFlower17 in the tflearn package. The dataset consists of 17 categories of flowers with 80 images for each class. It is a three dimensional data with RGB colour values per each pixel along with the width and height pixels."}),"\n",(0,a.jsx)(n.p,{children:"AlexNet Architecture"}),"\n",(0,a.jsx)(n.p,{children:"AlexNet consist of 5 convolutional layers and 3 dense layers. The data gets split into to 2 GPU cores. The image below is from the first reference the AlexNet Wikipedia page here."}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"AlexNet Architecture",src:t(28947).A+"",width:"932",height:"448"})}),"\n",(0,a.jsx)(n.p,{children:"AlexNet with Keras"}),"\n",(0,a.jsx)(n.p,{children:"I made a few changes in order to simplify a few things and further optimise the training outcome. First of all, I am using the sequential model and eliminating the parallelism for simplification. For example, the first convolutional layer has 2 layers with 48 neurons each. Instead, I am combining it to 98 neurons."}),"\n",(0,a.jsx)(n.p,{children:"The original architecture did not have batch normalisation after every layer (although it had normalisation between a few layers) and dropouts. I am putting the batch normalisation before the input after every layer and dropouts between the fully-connected layers to reduce over-fitting."}),"\n",(0,a.jsx)(n.p,{children:"When to use batch normalisation is difficult. Everyone seems to have opinions or evidence that supports their opinions. Without going into too much details, I decided to normalise before the input as it seems to make sense statistically."}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Code"})}),"\n",(0,a.jsx)(n.p,{children:"Here is the code example. The input data is 3-dimensional and then you need to flatten the data before passing it into the dense layer. Using cross-entropy for the loss function, adam for optimiser and accuracy for performance metrics."}),"\n",(0,a.jsx)(n.p,{children:"As the network is complex, it takes a long time to run. It took about 10 hours to run 250 epochs on my cheap laptop with CPU. The test dataset accuracy is not great. This is probably because we do not have enough datasets. I don\u2019t think 80 images each is enough for convolutional neural networks. But, it still runs."}),"\n",(0,a.jsx)(n.p,{children:"It\u2019s pretty amazing that what was the-state-of-the-art in 2012 can be done with a very little programming and run on your $700 laptops!"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"# (1) Importing dependency\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout, Flatten,\\\n Conv2D, MaxPooling2D\nfrom keras.layers.normalization import BatchNormalization\nimport numpy as np\nnp.random.seed(1000)\n\n# (2) Get Data\nimport tflearn.datasets.oxflower17 as oxflower17\nx, y = oxflower17.load_data(one_hot=True)\n\n# (3) Create a sequential model\nmodel = Sequential()\n\n# 1st Convolutional Layer\nmodel.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11),\\\n strides=(4,4), padding='valid'))\nmodel.add(Activation('relu'))\n# Pooling\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n# Batch Normalisation before passing it to the next layer\nmodel.add(BatchNormalization())\n\n# 2nd Convolutional Layer\nmodel.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid'))\nmodel.add(Activation('relu'))\n# Pooling\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n# Batch Normalisation\nmodel.add(BatchNormalization())\n\n# 3rd Convolutional Layer\nmodel.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\nmodel.add(Activation('relu'))\n# Batch Normalisation\nmodel.add(BatchNormalization())\n\n# 4th Convolutional Layer\nmodel.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\nmodel.add(Activation('relu'))\n# Batch Normalisation\nmodel.add(BatchNormalization())\n\n# 5th Convolutional Layer\nmodel.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\nmodel.add(Activation('relu'))\n# Pooling\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n# Batch Normalisation\nmodel.add(BatchNormalization())\n\n# Passing it to a dense layer\nmodel.add(Flatten())\n# 1st Dense Layer\nmodel.add(Dense(4096, input_shape=(224*224*3,)))\nmodel.add(Activation('relu'))\n# Add Dropout to prevent overfitting\nmodel.add(Dropout(0.4))\n# Batch Normalisation\nmodel.add(BatchNormalization())\n\n# 2nd Dense Layer\nmodel.add(Dense(4096))\nmodel.add(Activation('relu'))\n# Add Dropout\nmodel.add(Dropout(0.4))\n# Batch Normalisation\nmodel.add(BatchNormalization())\n\n# 3rd Dense Layer\nmodel.add(Dense(1000))\nmodel.add(Activation('relu'))\n# Add Dropout\nmodel.add(Dropout(0.4))\n# Batch Normalisation\nmodel.add(BatchNormalization())\n\n# Output Layer\nmodel.add(Dense(17))\nmodel.add(Activation('softmax'))\n\nmodel.summary()\n\n# (4) Compile\nmodel.compile(loss='categorical_crossentropy', optimizer='adam',\\\n metrics=['accuracy'])\n\n# (5) Train\nmodel.fit(x, y, batch_size=64, epochs=1, verbose=1, \\\nvalidation_split=0.2, shuffle=True)\n"})})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(c,{...e})}):c(e)}},28947:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/alexnet-architecture-be16abb393baa6c357e3d698298e3d99.png"},28453:(e,n,t)=>{t.d(n,{R:()=>l,x:()=>r});var a=t(96540);const i={},o=a.createContext(i);function l(e){const n=a.useContext(o);return a.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:l(e.components),a.createElement(o.Provider,{value:n},e.children)}}}]);