"use strict";(self.webpackChunkmydatahack_blog_site=self.webpackChunkmydatahack_blog_site||[]).push([[2739],{70034:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>r,default:()=>_,frontMatter:()=>i,metadata:()=>s,toc:()=>c});var a=n(74848),o=n(28453);const i={slug:"data-science/deep-learning//building-alexnet-with-tensorflow-and-running-it-with-aws-sagemaker",title:"Building AlexNet with TensorFlow and Running it with AWS SageMaker",tags:["Data Science","Deep Learning","AlexNet","Convolutional Neural Networks","Image Classification","SageMaker","TensorFlow"]},r=void 0,s={permalink:"/mydatahack-old-blog/data-science/data-science/deep-learning/building-alexnet-with-tensorflow-and-running-it-with-aws-sagemaker",source:"@site/data-science/deep-learning/2018-05-07-alexnet-tensorflow.md",title:"Building AlexNet with TensorFlow and Running it with AWS SageMaker",description:"In the last post, we built AlexNet with Keras. This is the second part of AlexNet building. Let\u2019s rewrite the Keras code from the previous post (see Building AlexNet with Keras) with TensorFlow and run it in AWS SageMaker instead of the local machine.",date:"2018-05-07T00:00:00.000Z",tags:[{label:"Data Science",permalink:"/mydatahack-old-blog/data-science/tags/data-science"},{label:"Deep Learning",permalink:"/mydatahack-old-blog/data-science/tags/deep-learning"},{label:"AlexNet",permalink:"/mydatahack-old-blog/data-science/tags/alex-net"},{label:"Convolutional Neural Networks",permalink:"/mydatahack-old-blog/data-science/tags/convolutional-neural-networks"},{label:"Image Classification",permalink:"/mydatahack-old-blog/data-science/tags/image-classification"},{label:"SageMaker",permalink:"/mydatahack-old-blog/data-science/tags/sage-maker"},{label:"TensorFlow",permalink:"/mydatahack-old-blog/data-science/tags/tensor-flow"}],readingTime:7.455,hasTruncateMarker:!0,authors:[],frontMatter:{slug:"data-science/deep-learning//building-alexnet-with-tensorflow-and-running-it-with-aws-sagemaker",title:"Building AlexNet with TensorFlow and Running it with AWS SageMaker",tags:["Data Science","Deep Learning","AlexNet","Convolutional Neural Networks","Image Classification","SageMaker","TensorFlow"]},unlisted:!1,prevItem:{title:"Building AlexNet with Keras",permalink:"/mydatahack-old-blog/data-science/data-science/deep-learning/building-alexnet-with-keras"},nextItem:{title:"Introduction to Dense Layers for Deep Learning with Keras",permalink:"/mydatahack-old-blog/data-science/data-science/deep-learning/introduction-to-dense-net-with-keras/"}},l={authorsImageUrls:[]},c=[];function d(e){const t={code:"code",p:"p",pre:"pre",strong:"strong",...(0,o.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(t.p,{children:"In the last post, we built AlexNet with Keras. This is the second part of AlexNet building. Let\u2019s rewrite the Keras code from the previous post (see Building AlexNet with Keras) with TensorFlow and run it in AWS SageMaker instead of the local machine."}),"\n",(0,a.jsx)(t.p,{children:"AlexNet is in fact too heavy for a regular commercial laptop to handle it. It only runs on a small dataset and takes for ages. By using the cloud service like AWS, we can access to much better computers without any hardware investment. AWS already has a series of deep learning specialised instances (P2 Instances). The smallest with one GPU (p2.xlarge) costs 90 cent per hour. It is much faster than CPU machines. You can experiment on computing capacities as you will be charged only by usage hours. If you are thinking about buying a more expensive GPU laptop for deep learning, the cloud services would be a better option."}),"\n",(0,a.jsx)(t.p,{children:"AWS recently released SageMaker, which enables you to develop and deploy deep learning code with no hustle. To run Tensorflow code in SageMaker, all you need is to create a notebook instance (check out the getting started video here)."}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.strong,{children:"Importing OxfordFlower17 Data"})}),"\n",(0,a.jsx)(t.p,{children:"You can creates a notebook instance with a chosen EC2 instance with SageMaker. Once the instance is created, you can access to the instance through Jupyter notebook for development and deployment. Many deep learning frameworks are already installed. Once you train the model, you can deploy it into the AWS environment without much hustle. The caveat is that you won\u2019t be able to install or update the preinstalled packages as you do not have access to the underlining instance. If you need to have special environmental requirements, you need to bring it in with a Docker container."}),"\n",(0,a.jsx)(t.p,{children:"In fact, SageMaker does not have tflearn installed. As in the previous post, we are importing 17 category flower dataset (OxfordFlower17) from tflearn. If you try to import it in SageMaker, it will give you the module not found error."}),"\n",(0,a.jsx)(t.p,{children:"The strategy I took here is to upload the dataset as numpy array files to S3 and retrieve them in SageMaker."}),"\n",(0,a.jsx)(t.p,{children:"(1) Create the numpy files and Upload to S3"}),"\n",(0,a.jsx)(t.p,{children:"I first created npy files and uploaded to S3 bucket where SageMaker has the access policy."}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:"# (1) Get dataset from s3 bucket\nimport tflearn.datasets.oxflower17 as oxflower17\nx, y = oxflower17.load_data(one_hot=True)\n\n# (2) save data as .npy files\nx_path='/tmp/oxford_flower_17_x.npy'\ny_path='/tmp/oxford_flower_17_y.npy'\nimport numpy as np\nnp.save(x_path, x)\nnp.save(y_path, y)\n\n# (3) push file to s3\nimport boto3\nimport botocore\n\nclient = boto3.client('s3')\ntarget_bucket = 'sagemaker.mydh'\nx_key = 'data/oxford_flower_17_x.npy'\ny_key = 'data/oxford_flower_17_y.npy'\n\n# Uploading\nclient.upload_file(Filename=x_path, Bucket=target_bucket, Key=x_key)\nprint('Completed Uploading {} to {}/{}'.format(x_path, target_bucket, x_key))\nclient.upload_file(Filename=y_path, Bucket=target_bucket, Key=y_key)\nprint('Completed Uploading {} to {}/{}'.format(y_path, target_bucket, y_key))\n"})}),"\n",(0,a.jsx)(t.p,{children:"(2) Import numpy files into the SageMaker instance."}),"\n",(0,a.jsx)(t.p,{children:"You can get the file from S3 into the Notebook instance and simply load them as numpy objects."}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:"import boto3\nimport botocore\n\ndef download_file_with_resource(bucket_name, key, local_path):\n    s3 = boto3.resource('s3')\n    s3.Bucket(bucket_name).download_file(key, local_path)\n    print('Downloaded {}'.format(key))\n\nbucket_name = 'sagemaker.mydh'\nx_key='data/oxford_flower_17_x.npy'\ny_key='data/oxford_flower_17_y.npy'\nx_local_path = './data/oxford_flower_17_x.npy'\ny_local_path = './data/oxford_flower_17_y.npy'\n\n# download_file_with_resource(bucket_name, 'data/check.csv', './data/check.csv')\ndownload_file_with_resource(bucket_name, x_key, x_local_path)\ndownload_file_with_resource(bucket_name, y_key, y_local_path)\n\n# (3) Load data\nx_local_path = './data/oxford_flower_17_x.npy'\ny_local_path = './data/oxford_flower_17_y.npy'\nx = np.load(x_local_path)\ny = np.load(y_local_path)\nprint('Shape of features: ', x.shape, 'Type: ', type(x))\nprint('Shape of classes: ', y.shape, 'Type: ', type(y))\n"})}),"\n",(0,a.jsx)(t.p,{children:"Code"}),"\n",(0,a.jsx)(t.p,{children:"Strictly speaking, it is slightly different from the original AlexNet. The code is sequential and has no parallel computing components for simplicity. I am doing batch normalisation before every input and doing dropouts in the Dense layer. The network architecture is the same as the previous post."}),"\n",(0,a.jsx)(t.p,{children:"With TensorFlow, you really need to be careful about the dimensions. The original dataset is 3-dimentional. After the convolution layers, the dimension is compressed from pooling. So, you need to specify the right dimension (7 x 7 in this case). Otherwise, the code will not run."}),"\n",(0,a.jsx)(t.p,{children:"In the model, I purposely included the weights and biases with hard-coded values so that it is easy to follow. Apart from the model, the same code used in building Dense Net for Iris works. If you need to understand other part of the codes you should read the previous post (Introduction to Dense Net with TensorFlow)."}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:"import tensorflow as tf\ntf.set_random_seed(1000)\nimport numpy as np\nnp.random.seed(1000)\nfrom sklearn.model_selection import train_test_split\n\n# (1) Create Training (80%), test (20%) and validation (20%) dataset\n#     Datasets (x and y) are loaded as numpy object from the previous step\nx_train, x_test_pre, y_train, y_test_pre = train_test_split(x, y, test_size=0.20, random_state=42)\nx_test, x_validation, y_test, y_validation = train_test_split(x_test_pre, y_test_pre, test_size=0.1)\n\n# Check Shapes\nprint('Shape: x_train={}, y_train={}'.format(x_train.shape, y_train.shape))\nprint('Shape: x_test={}, y_test={}'.format(x_test.shape, y_test.shape))\nprint('Shape: x_validation={}, y_validation={}'.format(x_validation.shape, y_validation.shape))\n\n# (2) Define the placeholder tensors\nx = tf.placeholder(tf.float32, [None, 224, 224, 3])\ny = tf.placeholder(tf.float32, [None, 17]) # no of flower speces in the dataset\n\n# (3) Define Layers\n# Convolutional Layer with Relu activation\ndef conv2D(x, W, b, stride_size):\n    xW = tf.nn.conv2d(x, W, strides=[1, stride_size, stride_size, 1],padding='SAME')\n    z = tf.nn.bias_add(xW, b)\n    a = tf.nn.relu(z)\n    return (a)\n\n# Max Pooling Layer\ndef maxPooling2D(x, kernel_size, stride_size):\n    return tf.nn.max_pool(x, ksize=[1, kernel_size, kernel_size, 1],\n                         strides=[1, stride_size, stride_size, 1],padding='SAME')\n\n# Dense Layer\ndef dense(x, W, b):\n    z = tf.add(tf.matmul(x, W), b)\n    a = tf.nn.relu(z)\n    return a\n\n# (4) Define AlexNet\n# Setting some parameters\nw_init = tf.contrib.layers.xavier_initializer()\nbatch_size = 8\nepochs = 1\nprogress = 40\nn_classes = 17\n\n# Function, x is the input features\ndef alexNet(img_input):\n\n    # 1st Convolutional Layer\n    w_c1 = tf.get_variable('w_c1', [11, 11, 3, 96], initializer=w_init)\n    b_c1 = tf.Variable(tf.zeros([96]))\n    c1 = conv2D(img_input, w_c1, b_c1, stride_size=4)\n    # Pooling\n    p1 = maxPooling2D(c1, kernel_size=2, stride_size=2)\n    # Batch Normalisation\n    bn1 = tf.contrib.layers.batch_norm(p1)\n\n    # 2nd Convolutional layer\n    w_c2 = tf.get_variable('w_c2', [5, 5, 96, 256], initializer=w_init)\n    b_c2 = tf.Variable(tf.zeros([256]))\n    c2 = conv2D(bn1, w_c2, b_c2, stride_size=1)\n    # Pooling\n    p2 = maxPooling2D(c2, kernel_size=2, stride_size=2)\n    # Batch Normalisation\n    bn2 = tf.contrib.layers.batch_norm(p2)\n\n    # 3rd Convolutional Layer\n    w_c3 = tf.get_variable('w_c3', [3, 3, 256, 384], initializer=w_init)\n    b_c3 = tf.Variable(tf.zeros([384]))\n    c3 = conv2D(bn2, w_c3, b_c3, stride_size=1)\n    # Batch Normalisation\n    bn3 = tf.contrib.layers.batch_norm(c3)\n\n    # 4th Convolutional Layer\n    w_c4 = tf.get_variable('w_c4', [3, 3, 384, 384], initializer=w_init)\n    b_c4 = tf.Variable(tf.zeros([384]))\n    c4 = conv2D(bn3, w_c4, b_c4, stride_size=1)\n    # Batch Normalisation\n    bn4 = tf.contrib.layers.batch_norm(c4)\n\n    # 5th Convolutional Layer\n    w_c5 = tf.get_variable('w_c5', [3, 3, 384, 256], initializer=w_init)\n    b_c5 = tf.Variable(tf.zeros([256]))\n    c5 = conv2D(bn4, w_c5, b_c5, stride_size=1)\n    # Pooling\n    p3 = maxPooling2D(c5, kernel_size=2, stride_size=2)\n    # Batch Normalisation\n    bn5 = tf.contrib.layers.batch_norm(p3)\n\n    # Flatten the conv layer - features has been reduced by pooling 3 times: 224/2*2*2\n    flattened = tf.reshape(bn5, [-1, 28*28*256])\n\n    # 1st Dense layer\n    w_d1 = tf.get_variable('w_d1', [28*28*256, 4096], initializer=w_init)\n    b_d1 = tf.Variable(tf.zeros([4096]))\n    d1 = dense(flattened, w_d1, b_d1)\n    # Dropout\n    dropout_d1 = tf.nn.dropout(d1, 0.6)\n\n    # 2nd Dense layer\n    w_d2 = tf.get_variable('w_d2', [4096, 4096], initializer=w_init)\n    b_d2 = tf.Variable(tf.zeros([4096]))\n    d2 = dense(dropout_d1, w_d2, b_d2)\n    # Dropout\n    dropout_d2 = tf.nn.dropout(d2, 0.6)\n\n    # 3rd Dense layer\n    w_d3 = tf.get_variable('w_d3', [4096, 1000], initializer=w_init)\n    b_d3 = tf.Variable(tf.zeros([1000]))\n    d3 = dense(dropout_d2, w_d3, b_d3)\n    # Dropout\n    dropout_d3 = tf.nn.dropout(d3, 0.6)\n\n    # Output layer\n    w_out = tf.get_variable('w_out', [1000, n_classes], initializer=w_init)\n    b_out = tf.Variable(tf.zeros([n_classes]))\n    out = tf.add(tf.matmul(dropout_d3, w_out), b_out)\n\n    return out\n\n# (5) Build model\npredictions = alexNet(x)\n\n# (6) Define model's cost and optimizer\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=predictions, labels=y))\noptimizer = tf.train.AdamOptimizer().minimize(cost)\n\n# (7) Defining evaluation metrics\ncorrect_prediction = tf.equal(tf.argmax(predictions, 1), tf.argmax(y, 1))\naccuracy_pct = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) * 100\n\n# (8) initialize\ninitializer_op = tf.global_variables_initializer()\n\n# (9) Run\nwith tf.Session() as session:\n    session.run(initializer_op)\n\n    print(\"Training for\", epochs, \"epochs.\")\n\n    # looping over epochs:\n    for epoch in range(epochs):\n        # To monitor performance during training\n        avg_cost = 0.0\n        avg_acc_pct = 0.0\n\n        # loop over all batches of the epoch- 1088 records\n        # batch_size = 128 is already defined\n        n_batches = int(1088 / batch_size)\n        counter = 1\n        for i in range(n_batches):\n\n            # Get the random int for batch\n            random_indices = np.random.randint(1088, size=batch_size) # 1088 is the no of training set records\n\n            feed = {\n                x: x_train[random_indices],\n                y: y_train[random_indices]\n            }\n\n            # feed batch data to run optimization and fetching cost and accuracy:\n            _, batch_cost, batch_acc = session.run([optimizer, cost, accuracy_pct],\n                                                   feed_dict=feed)\n            # Print batch cost to see the code is working (optional)\n            # print('Batch no. {}: batch_cost: {}, batch_acc: {}'.format(counter, batch_cost, batch_acc))\n            # Get the average cost and accuracy for all batches:\n            avg_cost += batch_cost / n_batches\n            avg_acc_pct += batch_acc / n_batches\n            counter += 1\n\n        # Get cost and accuracy after one iteration\n        test_cost = cost.eval({x: x_test, y: y_test})\n        test_acc_pct = accuracy_pct.eval({x: x_test, y: y_test})\n        # output logs at end of each epoch of training:\n        print(\"Epoch {}: Training Cost = {:.3f}, Training Acc = {:.2f} -- Test Cost = {:.3f}, Test Acc = {:.2f}\"\\\n              .format(epoch + 1, avg_cost, avg_acc_pct, test_cost, test_acc_pct))\n\n    # Getting Final Test Evaluation\n    print('\\n')\n    print(\"Training Completed. Final Evaluation on Test Data Set.\\n\")\n    test_cost = cost.eval({x: x_test, y: y_test})\n    test_accy_pct = accuracy_pct.eval({x: x_test, y: y_test})\n    print(\"Test Cost:\", '{:.3f}'.format(test_cost))\n    print(\"Test Accuracy: \", '{:.2f}'.format(test_accy_pct), \"%\", sep='')\n    print('\\n')\n\n    # Getting accuracy on Validation set\n    val_cost = cost.eval({x: x_validation, y: y_validation})\n    val_acc_pct = accuracy_pct.eval({x: x_validation, y: y_validation})\n    print(\"Evaluation on Validation Data Set.\\n\")\n    print(\"Evaluation Cost:\", '{:.3f}'.format(val_cost))\n    print(\"Evaluation Accuracy: \", '{:.2f}'.format(val_acc_pct), \"%\", sep='')\n"})})]})}function _(e={}){const{wrapper:t}={...(0,o.R)(),...e.components};return t?(0,a.jsx)(t,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},28453:(e,t,n)=>{n.d(t,{R:()=>r,x:()=>s});var a=n(96540);const o={},i=a.createContext(o);function r(e){const t=a.useContext(i);return a.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function s(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:r(e.components),a.createElement(i.Provider,{value:t},e.children)}}}]);