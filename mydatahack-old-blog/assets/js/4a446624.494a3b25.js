"use strict";(self.webpackChunkmydatahack_blog_site=self.webpackChunkmydatahack_blog_site||[]).push([[3204],{89013:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>s,default:()=>g,frontMatter:()=>r,metadata:()=>i,toc:()=>d});var o=n(74848),a=n(28453);const r={sidebar_position:6},s="REST API Data Ingestion with Node.js",i={id:"data-ingestion/rest-api-node",title:"REST API Data Ingestion with Node.js",description:"The classic REST API data ingestion pattern is (1) to make an API call to the endpoint, (2) get the data, (3) transform it to a structured table and (4) load it to a database. Let\u2019s have a go at it with Node.js. We are using JSONPlaceholder which offers a few different REST API endpoints for testing or experimenting. Let\u2019s ingest the photos dataset into Postgres database.",source:"@site/docs/data-ingestion/6.rest-api-node.md",sourceDirName:"data-ingestion",slug:"/data-ingestion/rest-api-node",permalink:"/mydatahack-old-blog/mydatahack-old-blog/data-ingestion/rest-api-node",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:6,frontMatter:{sidebar_position:6},sidebar:"tutorialSidebar",previous:{title:"How to Ingest Data From MongoDB with Node.js",permalink:"/mydatahack-old-blog/mydatahack-old-blog/data-ingestion/mong-node-2"},next:{title:"Converting JSON to CSV and Loading it to Postgres with Node.js",permalink:"/mydatahack-old-blog/mydatahack-old-blog/data-ingestion/json-to-csv-to-pg-node"}},c={},d=[];function l(e){const t={code:"code",h1:"h1",p:"p",pre:"pre",...(0,a.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(t.h1,{id:"rest-api-data-ingestion-with-nodejs",children:"REST API Data Ingestion with Node.js"}),"\n",(0,o.jsx)(t.p,{children:"The classic REST API data ingestion pattern is (1) to make an API call to the endpoint, (2) get the data, (3) transform it to a structured table and (4) load it to a database. Let\u2019s have a go at it with Node.js. We are using JSONPlaceholder which offers a few different REST API endpoints for testing or experimenting. Let\u2019s ingest the photos dataset into Postgres database."}),"\n",(0,o.jsx)(t.p,{children:"To make REST API calls to http endpoints, we can use the https module, which comes with Node.js installation and you do not need to install it."}),"\n",(0,o.jsx)(t.p,{children:"We are using node-postgres for connecting to Postgres, pg-copy-streams for bulk loading data, json2csv for converting JSON to CSV."}),"\n",(0,o.jsx)(t.p,{children:"Apart from making GET requests with https, all the data ingestion techniques in this blog have been covered in the previous posts. Check them out for further details."}),"\n",(0,o.jsx)(t.p,{children:"Bulk Loading Postgres with Node.js\nConverting JSON to CSV and Loading it to Postgres with Node.js\nOK, here comes the code."}),"\n",(0,o.jsx)(t.p,{children:"The GET request is an asynchronous function. During the function execution, we keep appending the incoming data to the buffer variable. Once the \u2018end\u2019 event is emitted, we convert the JSON data into CSV and load it to Postgres sequentially. This execution pattern works well."}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-js",children:'// Import required module\nconst fs = require("fs");\nconst path = require("path");\nconst https = require("https");\nconst Json2csvParser = require("json2csv").Parser;\nconst { Client } = require("pg");\nconst copyFrom = require("pg-copy-streams").from;\nconst config = require("./config.json");\n\n// File output path & api endpoint\nconst outputFile = path.join(__dirname, "/data/photos.csv");\nconst url = "https://jsonplaceholder.typicode.com/photos";\n\n// Define the field\nconst fields = ["albumId", "id", "title", "url", "thumbnailUrl"];\n\n// target table\nvar table = "usermanaged.photos";\n\n// Getting connectin parameters from config.json\nconst host = config.host;\nconst user = config.user;\nconst pw = config.pw;\nconst db = config.db;\nconst port = config.port;\nconst conString = `postgres://${user}:${pw}@${host}:${port}/${db}`;\n\n// Load data function\nconst executeQuery = (targetTable) => {\n  console.log("Starting executeQuery function");\n  // Connecting to Database\n  const client = new Client({\n    connectionString: conString,\n  });\n  client.connect();\n\n  const execute = (target, callback) => {\n    client.query(`Truncate ${target}`, (err) => {\n      if (err) {\n        client.end();\n        callback(err);\n        // return console.log(err.stack)\n      } else {\n        console.log(`Truncated ${target}`);\n        callback(null, target);\n      }\n    });\n  };\n  execute(targetTable, (err) => {\n    if (err) return console.log(`Error in Truncate Table: ${err}`);\n    var stream = client.query(\n      copyFrom(`COPY ${targetTable} FROM STDIN CSV HEADER`)\n    );\n    var fileStream = fs.createReadStream(outputFile);\n\n    fileStream.on("error", (error) => {\n      console.log(`Error in creating read stream ${error}`);\n      client.end();\n    });\n    stream.on("error", (error) => {\n      console.log(`Error in creating stream ${error}`);\n      client.end();\n    });\n    stream.on("end", () => {\n      console.log(`Completed loading data into ${targetTable}`);\n      client.end();\n    });\n    fileStream.pipe(stream);\n  });\n};\n\n// Main Logic Execution\nhttps.get(url, (res) => {\n  res.setEncoding("utf8");\n  let data = "";\n  res.on("data", (chunk) => {\n    data += chunk;\n  });\n  res.on("end", () => {\n    console.log("Starting Json to Csv Conversion...");\n    try {\n      // Converting Json response to CSV\n      const parser = new Json2csvParser({ fields });\n      const csv = parser.parse(JSON.parse(data));\n      // Create a csv file\n      fs.writeFileSync(outputFile, csv);\n      console.log(`Csv file has been created as ${outputFile}`);\n      // Load data into PG table\n      executeQuery(table);\n    } catch (err) {\n      console.error(err);\n    }\n  });\n});\n'})}),"\n",(0,o.jsx)(t.p,{children:"(2018-04-17)"})]})}function g(e={}){const{wrapper:t}={...(0,a.R)(),...e.components};return t?(0,o.jsx)(t,{...e,children:(0,o.jsx)(l,{...e})}):l(e)}},28453:(e,t,n)=>{n.d(t,{R:()=>s,x:()=>i});var o=n(96540);const a={},r=o.createContext(a);function s(e){const t=o.useContext(r);return o.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function i(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:s(e.components),o.createElement(r.Provider,{value:t},e.children)}}}]);