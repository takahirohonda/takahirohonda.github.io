<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-data-science" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.3.2">
<title data-rh="true">How To Deploy Spark Applications In AWS With EMR and Data Pipeline | MyDatahack</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://takahirohonda.github.io/mydatahack-old-blog/data-science/data-science/infra/how-to-deploy-spark-applications-in-aws-with-emr-and-data-pipeline"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="How To Deploy Spark Applications In AWS With EMR and Data Pipeline | MyDatahack"><meta data-rh="true" name="description" content="Once you create an awesome data science application, it is time for you to deploy it. There are many ways to productionise them. The focus here is deploying Spark applications by using the AWS big data infrastructure. From my experience with the AWS stack and Spark development, I will discuss some high level architectural view and use cases as well as development process flow."><meta data-rh="true" property="og:description" content="Once you create an awesome data science application, it is time for you to deploy it. There are many ways to productionise them. The focus here is deploying Spark applications by using the AWS big data infrastructure. From my experience with the AWS stack and Spark development, I will discuss some high level architectural view and use cases as well as development process flow."><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2018-01-04T00:00:00.000Z"><meta data-rh="true" property="article:tag" content="Data Science,Tools and Infrastructure,AWS,Data Pipeline,EMR,Spark"><link data-rh="true" rel="icon" href="/mydatahack-old-blog/img/icon-circle.png"><link data-rh="true" rel="canonical" href="https://takahirohonda.github.io/mydatahack-old-blog/data-science/data-science/infra/how-to-deploy-spark-applications-in-aws-with-emr-and-data-pipeline"><link data-rh="true" rel="alternate" href="https://takahirohonda.github.io/mydatahack-old-blog/data-science/data-science/infra/how-to-deploy-spark-applications-in-aws-with-emr-and-data-pipeline" hreflang="en"><link data-rh="true" rel="alternate" href="https://takahirohonda.github.io/mydatahack-old-blog/data-science/data-science/infra/how-to-deploy-spark-applications-in-aws-with-emr-and-data-pipeline" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","@id":"https://takahirohonda.github.io/mydatahack-old-blog/data-science/data-science/infra/how-to-deploy-spark-applications-in-aws-with-emr-and-data-pipeline","mainEntityOfPage":"https://takahirohonda.github.io/mydatahack-old-blog/data-science/data-science/infra/how-to-deploy-spark-applications-in-aws-with-emr-and-data-pipeline","url":"https://takahirohonda.github.io/mydatahack-old-blog/data-science/data-science/infra/how-to-deploy-spark-applications-in-aws-with-emr-and-data-pipeline","headline":"How To Deploy Spark Applications In AWS With EMR and Data Pipeline","name":"How To Deploy Spark Applications In AWS With EMR and Data Pipeline","description":"Once you create an awesome data science application, it is time for you to deploy it. There are many ways to productionise them. The focus here is deploying Spark applications by using the AWS big data infrastructure. From my experience with the AWS stack and Spark development, I will discuss some high level architectural view and use cases as well as development process flow.","datePublished":"2018-01-04T00:00:00.000Z","author":[],"keywords":[],"isPartOf":{"@type":"Blog","@id":"https://takahirohonda.github.io/mydatahack-old-blog/data-science","name":"Blog"}}</script><link rel="alternate" type="application/rss+xml" href="/mydatahack-old-blog/blog/rss.xml" title="MyDatahack RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/mydatahack-old-blog/blog/atom.xml" title="MyDatahack Atom Feed">



<link rel="alternate" type="application/rss+xml" href="/mydatahack-old-blog/web-technologies/rss.xml" title="MyDatahack RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/mydatahack-old-blog/web-technologies/atom.xml" title="MyDatahack Atom Feed">
<link rel="alternate" type="application/rss+xml" href="/mydatahack-old-blog/data-engineering/rss.xml" title="MyDatahack RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/mydatahack-old-blog/data-engineering/atom.xml" title="MyDatahack Atom Feed">
<link rel="alternate" type="application/rss+xml" href="/mydatahack-old-blog/data-science/rss.xml" title="MyDatahack RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/mydatahack-old-blog/data-science/atom.xml" title="MyDatahack Atom Feed">
<link rel="alternate" type="application/rss+xml" href="/mydatahack-old-blog/infrastructure/rss.xml" title="MyDatahack RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/mydatahack-old-blog/infrastructure/atom.xml" title="MyDatahack Atom Feed"><link rel="stylesheet" href="/mydatahack-old-blog/assets/css/styles.2668ea1a.css">
<script src="/mydatahack-old-blog/assets/js/runtime~main.65edbf1e.js" defer="defer"></script>
<script src="/mydatahack-old-blog/assets/js/main.ffa8a442.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/mydatahack-old-blog/"><div class="navbar__logo"><img src="/mydatahack-old-blog/img/icon-circle.png" alt="MyDatahack Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/mydatahack-old-blog/img/icon-circle.png" alt="MyDatahack Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">MyDatahack</b></a><a class="navbar__item navbar__link" href="/mydatahack-old-blog/docs/">Blogs</a><a class="navbar__item navbar__link" href="/mydatahack-old-blog/web-technologies">Web Technologies</a><a class="navbar__item navbar__link" href="/mydatahack-old-blog/data-engineering">Data Engineering</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/mydatahack-old-blog/data-science">Data Science</a><a class="navbar__item navbar__link" href="/mydatahack-old-blog/infrastructure">Infrastructure</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/takahirohonda" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_pO2u margin-bottom--md">Posts</div><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/mydatahack-old-blog/data-science/data-science/deep-learning/building-alexnet-with-keras">Building AlexNet with Keras</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/mydatahack-old-blog/data-science/data-science/deep-learning/building-alexnet-with-tensorflow-and-running-it-with-aws-sagemaker">Building AlexNet with TensorFlow and Running it with AWS SageMaker</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/mydatahack-old-blog/data-science/data-science/deep-learning/introduction-to-dense-net-with-keras/">Introduction to Dense Layers for Deep Learning with Keras</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/mydatahack-old-blog/data-science/data-science/deep-learning/introduction-to-dense-net-with-tensorflow">Introduction to Dense Layers for Deep Learning with TensorFlow</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/mydatahack-old-blog/data-science/data-science/infra/how-to-create-your-personal-data-science-computing-environment-in-aws">How To Create Your Own Personal Data Science Computing Environment In AWS</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/mydatahack-old-blog/data-science/data-science/machine-learning/predict-internet-popularity-by-optimising-neural-networks-with-python">Predict Internet Popularity By Optimising Neural Networks With Python</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/mydatahack-old-blog/data-science/data-science/machine-learning/predict-internet-popularity-by-optimising-neural-networks-with-r">Predict Internet Popularity By Optimising Neural Networks With R</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/mydatahack-old-blog/data-science/data-science/machine-learning/how-to-save-machine-learning-models-in-r">How To Save Machine Learning Models In R</a></li><li class="sidebarItem__DBe"><a aria-current="page" class="sidebarItemLink_mo7H sidebarItemLinkActive_I1ZP" href="/mydatahack-old-blog/data-science/data-science/infra/how-to-deploy-spark-applications-in-aws-with-emr-and-data-pipeline">How To Deploy Spark Applications In AWS With EMR and Data Pipeline</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/mydatahack-old-blog/data-science/data-science/visualisation/how-to-do-sentiment-analysis-on-your-favourite-book-with-r">How To Do Sentiment Analysis On Your Favourite Book With R</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/mydatahack-old-blog/data-science/data-science/visualisation/how-to-create-a-word-cloud-for-your-favourite-book-with-r">How To Create a Word Cloud For Your Favourite Book With R</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/mydatahack-old-blog/data-science/data-science/visualisation/how-to-customise-shinyapp-with-bootstrap-css-javascript-and-plotly">How To Customise ShinyApp With Bootstrap, Javascript And Plotly</a></li></ul></nav></aside><main class="col col--7"><article><header><h1 class="title_f1Hy">How To Deploy Spark Applications In AWS With EMR and Data Pipeline</h1><div class="container_mt6G margin-vert--md"><time datetime="2018-01-04T00:00:00.000Z">January 4, 2018</time> Â· <!-- -->6 min read</div></header><div id="__blog-post-container" class="markdown"><p>Once you create an awesome data science application, it is time for you to deploy it. There are many ways to productionise them. The focus here is deploying Spark applications by using the AWS big data infrastructure. From my experience with the AWS stack and Spark development, I will discuss some high level architectural view and use cases as well as development process flow.</p>
<p>AWS offers a solid ecosystem to support Big Data processing and analytics, including EMR, S3, Redshift, DynamoDB and Data Pipeline. If you have a Spark application that runs on EMR daily, Data Pipleline enables you to execute it in the serverless manner.</p>
<p>The serverless architecture doesnâ€™t strictly mean there is no server. When the code is running, you of course need a server to run it. The main difference from the traditional way is that you store your codes and models in a repository, launch the server only during execution and close it as soon as it finishes. In this architecture, you only pay for the cost for the length of code execution. The architecture is often used for real-time data streaming or integration. AWS Lambda and Kinesis are good examples.</p>
<p>What is good about Data Pipeline?</p>
<p>Data Pipleline is a great tool to use the serverless architecture for batch jobs that run on schedule. You can design the pipeline job to control resources, workflow, execution dependency, scheduling and error handling without the hustle of provisioning and managing servers and the cost of keeping them running all the time.</p>
<p>Another advantage is that you can create a job with parameters (e.g. DB connection URLs, credentials, target schema/table). Data Pipeline jobs are basically JSON files. You can easily export and edit it. With parameters, you can easily promote jobs from the development environment to the production as it is a matter of importing the JSON file from dev to prod (which of course can be coded up for automation).</p>
<p>I also found that debugging and updating Spark codes or models became simpler. We can simply update the repo without touching the pipeline.</p>
<p>The cost of running Data Pipeline jobs is affordable. For a low frequency job (once a day), it costs 60 cent per month as of today. See the link for the pricing information. Note that the cost of running EMR will be charged at hourly rate on top of the running cost of pipelines.</p>
<p>Letâ€™s have a look at the use cases.</p>
<p>Use Case 1</p>
<p>Sourcing the data from different databases (application database, data lake and data warehouse) and joining them prior to running the algorithm.
The output needs to be presented in a BI tool.
Prerequisite</p>
<p>Save your Sqoop code (as .sh), Spark code and model to Bitbucet or GitHub (or S3, which is less preferable option).</p>
<p>Solution</p>
<p>Within the Data Pipeline, you can create a job to do below:</p>
<p>Launch a ERM cluster with Sqoop and Spark. Source the Sqoop code to EMR and execute it to move the data to S3.
Source the Spark code and model into EMR from a repo (e.g. Bitbucket, GitHub, S3). Execute the code, which transform the data and create output according to the pre-developed model.
Move the output of the Spark application to S3 and execute copy command to Redshift.
BI tools to fetch the output from Redshift for presentation.
Sqoop is a command line tool to transfer data between Hadoop and relational databases. EMR uses Hadoop for file management. So, it is the best tool to move the data from relational databases through Hadoop in EMR to S3. It is fast and easy to learn. I learned everything about Sqoop from a cookbook which you can download for free here.</p>
<p>Below image not working with docusaurus compilation ðŸ˜¢</p>
<p>Use Case 2</p>
<p>Ingesting data into Data Lake with an ETL tool.
Transforming data with ETL or ELT within the Redshift.
All the data required for the Spark application is in the data warehousing layer.
In the enterprise environment, it is common to have an ETL tool that manage the data ingestion and transformation. Accessing the application databases directly for analytics is not the best architectural practice, either. The first use case is suitable when you need to do data ingestion in an ad-hoc manner or cannot wait for ETL development for the sake of speedy delivery.</p>
<p>Prerequisite</p>
<p>The same as Use Case 1.</p>
<p>Solution</p>
<p>The figure shows Informatica as an ETL tool. There are heaps of options out there and any tool that suits your use case is fine. I compared DataStage, Informatica and Talend in the past and found Informatica best suited for the particular situation I was in. I especially liked the Redshift connector and I wrote a small review.</p>
<p>The workflow has two parts, managed by an ETL tool and Data Pipeline.</p>
<p>ETL Tool manages below:</p>
<p>ETL tool does data ingestion from source systems.
Do ETL or ELT within Redshift for transformation.
Unload any transformed data into S3.
Data Pipeline manages below:</p>
<p>Launch a cluster with Spark, source codes &amp; models from a repo and execute them. The output is moved to S3.
Copy data from S3 to Redshift (you can execute copy commands in the Spark code or Data Pipeline).
Then, you can source the output into a BI tool for presentation.</p>
<p><img decoding="async" loading="lazy" alt="informatica" src="/mydatahack-old-blog/assets/images/informatica-8a801a27dd2eb6358318312536b15810.png" width="1264" height="604" class="img_ev3q"></p>
<p>Development Process Workflow</p>
<p>Finally, letâ€™s have a look at development process workflow. Prior to Spark application deployment, we still need to develop and test the application in an EMR cluster. In this workflow, we only launch the cluster after prototyping on the local machine with a smaller dataset. This will save money as running an EMR cluster is expensive.</p>
<p>Once the code and models are developed, we can close the EMR cluster and move onto the serverless execution in batch. Codes and models can be source from S3 in the Data Pipeline. It is a standard practice to version control them in a git type repository. Sourcing them from a repo in Data Pipeline makes more sense.</p>
<p><img decoding="async" loading="lazy" alt="Data Science workflow with EMR" src="/mydatahack-old-blog/assets/images/ds-workflow-with-emr-eab8a50459ebe8992e73c227abff7f0f.png" width="1110" height="650" class="img_ev3q"></p>
<p>Let us know your experience with data science application deployment!</p></div><footer class="docusaurus-mt-lg"><div class="row margin-top--sm theme-blog-footer-edit-meta-row"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/mydatahack-old-blog/data-science/tags/data-science">Data Science</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/mydatahack-old-blog/data-science/tags/tools-and-infrastructure">Tools and Infrastructure</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/mydatahack-old-blog/data-science/tags/aws">AWS</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/mydatahack-old-blog/data-science/tags/data-pipeline">Data Pipeline</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/mydatahack-old-blog/data-science/tags/emr">EMR</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/mydatahack-old-blog/data-science/tags/spark">Spark</a></li></ul></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/mydatahack-old-blog/data-science/data-science/machine-learning/how-to-save-machine-learning-models-in-r"><div class="pagination-nav__sublabel">Newer Post</div><div class="pagination-nav__label">How To Save Machine Learning Models In R</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/mydatahack-old-blog/data-science/data-science/visualisation/how-to-do-sentiment-analysis-on-your-favourite-book-with-r"><div class="pagination-nav__sublabel">Older Post</div><div class="pagination-nav__label">How To Do Sentiment Analysis On Your Favourite Book With R</div></a></nav></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/mydatahack-old-blog/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/takahirohonda" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright Â© 2024 MDH.</div></div></div></footer></div>
</body>
</html>