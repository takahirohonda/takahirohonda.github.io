<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-data-science" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.3.2">
<title data-rh="true">How To Create a Word Cloud For Your Favourite Book With R | MyDatahack</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://takahirohonda.github.io/mydatahack-old-blog/data-science/data-science/visualisation/how-to-create-a-word-cloud-for-your-favourite-book-with-r"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="How To Create a Word Cloud For Your Favourite Book With R | MyDatahack"><meta data-rh="true" name="description" content="Making a word cloud is fun and easy. It is a way of looking at text data and gain a different perspective. For example, if you have a bunch of customer feedback about your product, you can quickly create a word cloud to get some ideas. When I work with text data, it is often the first step I do to quickly show business users something or to simply get the feeling before I get into more advanced analysis such as sentiment analysis or machine learning."><meta data-rh="true" property="og:description" content="Making a word cloud is fun and easy. It is a way of looking at text data and gain a different perspective. For example, if you have a bunch of customer feedback about your product, you can quickly create a word cloud to get some ideas. When I work with text data, it is often the first step I do to quickly show business users something or to simply get the feeling before I get into more advanced analysis such as sentiment analysis or machine learning."><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2018-01-02T00:00:00.000Z"><meta data-rh="true" property="article:tag" content="Data Science,R,Text Analytics,Word Cloud,Visualisation"><link data-rh="true" rel="icon" href="/mydatahack-old-blog/img/icon-circle.png"><link data-rh="true" rel="canonical" href="https://takahirohonda.github.io/mydatahack-old-blog/data-science/data-science/visualisation/how-to-create-a-word-cloud-for-your-favourite-book-with-r"><link data-rh="true" rel="alternate" href="https://takahirohonda.github.io/mydatahack-old-blog/data-science/data-science/visualisation/how-to-create-a-word-cloud-for-your-favourite-book-with-r" hreflang="en"><link data-rh="true" rel="alternate" href="https://takahirohonda.github.io/mydatahack-old-blog/data-science/data-science/visualisation/how-to-create-a-word-cloud-for-your-favourite-book-with-r" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","@id":"https://takahirohonda.github.io/mydatahack-old-blog/data-science/data-science/visualisation/how-to-create-a-word-cloud-for-your-favourite-book-with-r","mainEntityOfPage":"https://takahirohonda.github.io/mydatahack-old-blog/data-science/data-science/visualisation/how-to-create-a-word-cloud-for-your-favourite-book-with-r","url":"https://takahirohonda.github.io/mydatahack-old-blog/data-science/data-science/visualisation/how-to-create-a-word-cloud-for-your-favourite-book-with-r","headline":"How To Create a Word Cloud For Your Favourite Book With R","name":"How To Create a Word Cloud For Your Favourite Book With R","description":"Making a word cloud is fun and easy. It is a way of looking at text data and gain a different perspective. For example, if you have a bunch of customer feedback about your product, you can quickly create a word cloud to get some ideas. When I work with text data, it is often the first step I do to quickly show business users something or to simply get the feeling before I get into more advanced analysis such as sentiment analysis or machine learning.","datePublished":"2018-01-02T00:00:00.000Z","author":[],"keywords":[],"isPartOf":{"@type":"Blog","@id":"https://takahirohonda.github.io/mydatahack-old-blog/data-science","name":"Blog"}}</script><link rel="alternate" type="application/rss+xml" href="/mydatahack-old-blog/blog/rss.xml" title="MyDatahack RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/mydatahack-old-blog/blog/atom.xml" title="MyDatahack Atom Feed">



<link rel="alternate" type="application/rss+xml" href="/mydatahack-old-blog/web-technologies/rss.xml" title="MyDatahack RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/mydatahack-old-blog/web-technologies/atom.xml" title="MyDatahack Atom Feed">
<link rel="alternate" type="application/rss+xml" href="/mydatahack-old-blog/data-engineering/rss.xml" title="MyDatahack RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/mydatahack-old-blog/data-engineering/atom.xml" title="MyDatahack Atom Feed">
<link rel="alternate" type="application/rss+xml" href="/mydatahack-old-blog/data-science/rss.xml" title="MyDatahack RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/mydatahack-old-blog/data-science/atom.xml" title="MyDatahack Atom Feed">
<link rel="alternate" type="application/rss+xml" href="/mydatahack-old-blog/infrastructure/rss.xml" title="MyDatahack RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/mydatahack-old-blog/infrastructure/atom.xml" title="MyDatahack Atom Feed"><link rel="stylesheet" href="/mydatahack-old-blog/assets/css/styles.2668ea1a.css">
<script src="/mydatahack-old-blog/assets/js/runtime~main.65edbf1e.js" defer="defer"></script>
<script src="/mydatahack-old-blog/assets/js/main.ffa8a442.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/mydatahack-old-blog/"><div class="navbar__logo"><img src="/mydatahack-old-blog/img/icon-circle.png" alt="MyDatahack Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/mydatahack-old-blog/img/icon-circle.png" alt="MyDatahack Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">MyDatahack</b></a><a class="navbar__item navbar__link" href="/mydatahack-old-blog/docs/">Blogs</a><a class="navbar__item navbar__link" href="/mydatahack-old-blog/web-technologies">Web Technologies</a><a class="navbar__item navbar__link" href="/mydatahack-old-blog/data-engineering">Data Engineering</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/mydatahack-old-blog/data-science">Data Science</a><a class="navbar__item navbar__link" href="/mydatahack-old-blog/infrastructure">Infrastructure</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/takahirohonda" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_pO2u margin-bottom--md">Posts</div><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/mydatahack-old-blog/data-science/data-science/deep-learning/building-alexnet-with-keras">Building AlexNet with Keras</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/mydatahack-old-blog/data-science/data-science/deep-learning/building-alexnet-with-tensorflow-and-running-it-with-aws-sagemaker">Building AlexNet with TensorFlow and Running it with AWS SageMaker</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/mydatahack-old-blog/data-science/data-science/deep-learning/introduction-to-dense-net-with-keras/">Introduction to Dense Layers for Deep Learning with Keras</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/mydatahack-old-blog/data-science/data-science/deep-learning/introduction-to-dense-net-with-tensorflow">Introduction to Dense Layers for Deep Learning with TensorFlow</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/mydatahack-old-blog/data-science/data-science/infra/how-to-create-your-personal-data-science-computing-environment-in-aws">How To Create Your Own Personal Data Science Computing Environment In AWS</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/mydatahack-old-blog/data-science/data-science/machine-learning/predict-internet-popularity-by-optimising-neural-networks-with-python">Predict Internet Popularity By Optimising Neural Networks With Python</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/mydatahack-old-blog/data-science/data-science/machine-learning/predict-internet-popularity-by-optimising-neural-networks-with-r">Predict Internet Popularity By Optimising Neural Networks With R</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/mydatahack-old-blog/data-science/data-science/machine-learning/how-to-save-machine-learning-models-in-r">How To Save Machine Learning Models In R</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/mydatahack-old-blog/data-science/data-science/infra/how-to-deploy-spark-applications-in-aws-with-emr-and-data-pipeline">How To Deploy Spark Applications In AWS With EMR and Data Pipeline</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/mydatahack-old-blog/data-science/data-science/visualisation/how-to-do-sentiment-analysis-on-your-favourite-book-with-r">How To Do Sentiment Analysis On Your Favourite Book With R</a></li><li class="sidebarItem__DBe"><a aria-current="page" class="sidebarItemLink_mo7H sidebarItemLinkActive_I1ZP" href="/mydatahack-old-blog/data-science/data-science/visualisation/how-to-create-a-word-cloud-for-your-favourite-book-with-r">How To Create a Word Cloud For Your Favourite Book With R</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/mydatahack-old-blog/data-science/data-science/visualisation/how-to-customise-shinyapp-with-bootstrap-css-javascript-and-plotly">How To Customise ShinyApp With Bootstrap, Javascript And Plotly</a></li></ul></nav></aside><main class="col col--7"><article><header><h1 class="title_f1Hy">How To Create a Word Cloud For Your Favourite Book With R</h1><div class="container_mt6G margin-vert--md"><time datetime="2018-01-02T00:00:00.000Z">January 2, 2018</time> · <!-- -->7 min read</div></header><div id="__blog-post-container" class="markdown"><p>Making a word cloud is fun and easy. It is a way of looking at text data and gain a different perspective. For example, if you have a bunch of customer feedback about your product, you can quickly create a word cloud to get some ideas. When I work with text data, it is often the first step I do to quickly show business users something or to simply get the feeling before I get into more advanced analysis such as sentiment analysis or machine learning.</p>
<p>Creating a word cloud for your favourite book is even more fun if you are a book lover. It is another way to get to know your book and gives you a new creative perspective. In this post, I am building a word cloud from On The Road by Jack Kerouac. This is one of my favourite books. It is beautiful, ragged and free.</p>
<p>The simplest way of building word cloud is counting individual words that appear in the document. The more frequent a word appears on the book, the bigger the size of the word becomes in the cloud. To accomplish this task, you first need to download your favourite book and read it into the memory, process it into an appropriate format, and visualise it. The process is relatively simple. In R, the tm package pretty much handles processing and formatting of text data and the wordcloud package handles the creation of word cloud.</p>
<p>There are heaps of instruction available online, too. Here is the super simple introduction to word cloud with R from R-bloggers. This post will go further into the customisation of the word cloud and the creation of a document term matrix.</p>
<p>OK, enough intro. Let’s get to coding.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-summary">Step Summary<a href="#step-summary" class="hash-link" aria-label="Direct link to Step Summary" title="Direct link to Step Summary">​</a></h3>
<ul>
<li>Obtain free pdf copy of On The Road online.</li>
<li>Convert pdf into text data.</li>
<li>Split it by a new line, convert it into data frame and do clean up.</li>
<li>Create corpus and do pre-processing with tm.</li>
<li>Build word cloud.</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="steps">Steps<a href="#steps" class="hash-link" aria-label="Direct link to Steps" title="Direct link to Steps">​</a></h3>
<p>(1) I used freeditorial.com to get a copy of On The Road. You can also check out Project Gutenberg, which offers heaps of free books for downloading. If you are into Jane Austin, R has a package (janeaustenr) that contains her complete works and prepped for text analytics. The harrypotter package offers the full text of the first seven Harry Potter books.</p>
<p>After downloading the pdf file, I used pdftools to convert it into text. It converts each page into a vector element. It is a great package to read pdf with R.</p>
<div class="language-R language-r codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-r codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">library(pdftools)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">download.file(&quot;https://freeditorial.com/en/books/on-the-road/downloadbookepub/pdf&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">              &quot;/tmp/on_the_road.pdf&quot;, mode = &quot;wb&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">txt &lt;- pdf_text(&#x27;/tmp/on_the_road.pdf&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">(2) Split the text by new line and create a data frame. Once you have a data frame, it becomes easier to do clean up. I removed the title page, chapter title and the last two lines which are not the part of the novel. I also removed some special characters. I kept the chapter number because this can be dealt with tm later. For this part, you really need to look at the pdf you download and decide what to remove. When you use strisplit, make sure to add carrage return with new line for Windows like \r\n. For Linux and Unix, \n is sufficient.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">vec &lt;- character()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">for(i in 2:length(txt)){</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    tmp &lt;- strsplit(txt[i], &#x27;\n&#x27;) #\r\n for Windows</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    for(line in tmp){</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        vec &lt;- c(vec, line)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">lines &lt;- data.frame(vec)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">len &lt;- length(lines$vec)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">lines &lt;- subset(lines, !grepl(&#x27;PART&#x27;, vec))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">lines$vec &lt;- as.character(trimws(lines$vec, &#x27;both&#x27;))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">lines &lt;- as.data.frame(lines[-c(len, len-1),]) # Remove the last two lines (not part of the novel)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">colnames(lines) &lt;- c(&#x27;vec&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">lines$vec &lt;- gsub(&quot;Â«&quot;, &quot;&quot;, gsub(&quot;Â»&quot;, &quot;&quot;, lines$vec))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">(3) Create a corpus and do pre-processing (remove punctuation, numbers and stopwords and converting all words to lower case). Stemming is important for machine learning like spam identification. For a word cloud, it generates truncated words and looks wired. So, I always omit it.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">library(tm)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">library(SnowballC)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">library(wordcloud)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">corpus &lt;- Corpus(VectorSource(lines$vec))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">corpus &lt;- tm_map(corpus, PlainTextDocument)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">corpus &lt;- tm_map(corpus, removePunctuation)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">corpus &lt;- tm_map(corpus, removeNumbers)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">corpus &lt;- tm_map(corpus, content_transformer(tolower))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">corpus &lt;- tm_map(corpus, removeWords, stopwords(&#x27;english&#x27;))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># corpus &lt;- tm_map(corpus, stemDocument) - skip this one!</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">corpus &lt;- tm_map(corpus, stripWhitespace)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>(4) To create a word cloud, you can simply pass corpus to the wordcloud function. For colour, I created my own colour vector and randomiser so that colour changes randomly every time I run it. You can use RColorBrewer (see Step 5), but I found none of them really gives me the colour combos that I want. I set min.freq = 80 and max.words = 100. 100 words per word cloud is a good place to start. I usually determine min.freq by looking at the document term matrix (see step 6). The example below creates a png file, which is better than generating the cloud in the viewer. By default, the file is saved by the path of the current R session (check it with the getwd function).</p>
<div class="language-R language-r codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-r codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">colors &lt;- c(&quot;blue&quot;, &quot;blue3&quot;, &quot;blue4&quot;, &quot;blueviolet&quot;, &quot;brown1&quot;, &quot;brown2&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &quot;brown3&quot;, &quot;cyan3&quot;, &quot;cyan4&quot;, &quot;darkgoldenrod3&quot;, &quot;darkgoldenrod4&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &quot;chocolate2&quot;, &quot;chocolate3&quot;, &quot;chocolate1&quot;, &quot;chartreuse3&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &quot;chartreuse3&quot;, &quot;coral2&quot;, &quot;coral3&quot;, &quot;coral4&quot;,&quot;cornflowerblue&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &quot;darkmagenta&quot;, &quot;darkorchid2&quot;, &quot;darkorchid3&quot;, &quot;darkorchid4&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &quot;deeppink1&quot;, &quot;deeppink2&quot;, &quot;deeppink3&quot;,&quot;deepskyblue2&quot;, &quot;deepskyblue3&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &quot;deepskyblue4&quot;, &quot;dodgerblue4&quot;, &quot;dodgerblue3&quot;, &quot;dodgerblue2&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &quot;firebrick1&quot;, &quot;firebrick2&quot;, &quot;firebrick3&quot;, &quot;green3&quot;, &quot;green4&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &quot;hotpink&quot;, &quot;hotpink3&quot;, &quot;hotpink4&quot;, &quot;lightseagreen&quot;, &quot;lightslateblue&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &quot;purple&quot;, &quot;purple1&quot;, &quot;purple2&quot;, &quot;purple3&quot;, &quot;purple4&quot;, &quot;red&quot;, &quot;red1&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &quot;red2&quot;, &quot;red3&quot;, &quot;red4&quot;, &quot;turquoise4&quot;, &quot;turquoise2&quot;, &quot;violetred1&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &quot;violetred2&quot;, &quot;violetred3&quot;, &quot;violetred4&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">png(&quot;wordcloud_on_the_road.png&quot;, width=1280,height=800)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">color_vector1 &lt;- sample(colors, 20)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">wordcloud(corpus, max.words = 100, min.freq = 80, random.order = FALSE,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          color = color_vector1, rot.per = 0.15, scale = c(10,1.5))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">dev.off()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(&quot;Wordcloud png file has been generated.&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">(5) Here is the example of using RColorBrewer for a word cloud.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">png(&quot;wordcloud_on_the_road2.png&quot;, width=1280,height=800)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">color_vector1 &lt;- sample(colors, 20)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">wordcloud(corpus, max.words = 100, min.freq = 80, random.order = FALSE,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          color = brewer.pal(12, &quot;Set3&quot;), rot.per = 0.15, scale = c(10,1.5))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">dev.off()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(&quot;Wordcloud png file with RColorBrewer has been generated.&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">(6) A document term matrix has all the words in the text as columns and each line as rows. If a word appears in the row, it puts 1. To create a word count, you can simply aggregate it by columns. The wordcloud function takes column names and column sum as argument instead of corpus as below.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">png(&quot;wordcloud_on_the_road2.png&quot;, width=1280,height=800)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">color_vector1 &lt;- sample(colors, 20)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">wordcloud(corpus, max.words = 100, min.freq = 80, random.order = FALSE,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          color = brewer.pal(12, &quot;Set3&quot;), rot.per = 0.15, scale = c(10,1.5))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">dev.off()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(&quot;Wordcloud png file with RColorBrewer has been generated.&quot;)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>You can sort the aggregated data frame to check if the word cloud looks right according to word frequencies.</p>
<p><img decoding="async" loading="lazy" alt="word count example" src="/mydatahack-old-blog/assets/images/dtm_df_sum-c04531c07173a9bafaf26774dc427390.webp" width="299" height="160" class="img_ev3q"></p>
<p>I also use it to determin the min.freq parameter. 89 words exist for more than 80 frequencies. Hence, I used 80 as min.freq. Each text is different and it is best to check it so that you don’t miss out on words.</p>
<p>Creating DTM is the first step for machine learning on text data (but make sure to include stemming, which is the step I skipped for the word cloud).</p>
<div class="language-R language-r codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-r codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">frequencies &lt;- DocumentTermMatrix(corpus)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">dtm_df &lt;- as.data.frame(as.matrix(frequencies))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">dtm_df_sum &lt;- as.data.frame(apply(dtm_df, 2, sum))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">colnames(dtm_df_sum) &lt;- c(&quot;Frequency_Count&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">words &lt;- rownames(dtm_df_sum)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">rownames(dtm_df_sum) &lt;- NULL</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">dtm_df_sum &lt;- cbind(dtm_df_sum, words)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">dtm_df_sum &lt;- dtm_df_sum[order(dtm_df_sum$Frequency_Count, decreasing=T),]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">nrow(subset(dtm_df_sum, Frequency_Count &gt;= 100))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">nrow(subset(dtm_df_sum, Frequency_Count &gt;= 80))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">nrow(subset(dtm_df_sum, Frequency_Count &gt;= 50))</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Here are the word cloud I generated. Most of the books, you will see the characters’ name appearing as the most frequently used word. As expected, you can see dean as the biggest word as the story is centred on the madman, Dean Moriarty. The word cloud sort of makes sense to me. A lot of talking in the book, hence said is the second most frequently used word. Dean always goes back or comes back, hence back comes third. They are always on the move traveling across America, hence the words like went, going, see, around, road, car, way, people, girls, everybody and miles are frequently used words. This is so cool!</p>
<p>Custom Colour</p>
<p><img decoding="async" loading="lazy" alt="word cloud 1" src="/mydatahack-old-blog/assets/images/word-cloud-1-1ac19ac3e270143457c0d3fd8bc95f00.webp" width="673" height="589" class="img_ev3q"></p>
<p>RColorBrewer (Set3)</p>
<p><img decoding="async" loading="lazy" alt="word cloud 2" src="/mydatahack-old-blog/assets/images/word-cloud-2-4becd7076c880c2d81471caa6da24b9d.webp" width="785" height="696" class="img_ev3q"></p>
<p>I prefer using my own colour selections than any of the RColorBrewer palette as the palette sometimes give me the colours that are hard to read!</p>
<p>Now it’s your turn to create a word cloud for your favourite book!</p>
<p>The next step is learning how to do sentiment analysis on your favourite book!</p></div><footer class="docusaurus-mt-lg"><div class="row margin-top--sm theme-blog-footer-edit-meta-row"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/mydatahack-old-blog/data-science/tags/data-science">Data Science</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/mydatahack-old-blog/data-science/tags/r">R</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/mydatahack-old-blog/data-science/tags/text-analytics">Text Analytics</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/mydatahack-old-blog/data-science/tags/word-cloud">Word Cloud</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/mydatahack-old-blog/data-science/tags/visualisation">Visualisation</a></li></ul></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/mydatahack-old-blog/data-science/data-science/visualisation/how-to-do-sentiment-analysis-on-your-favourite-book-with-r"><div class="pagination-nav__sublabel">Newer Post</div><div class="pagination-nav__label">How To Do Sentiment Analysis On Your Favourite Book With R</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/mydatahack-old-blog/data-science/data-science/visualisation/how-to-customise-shinyapp-with-bootstrap-css-javascript-and-plotly"><div class="pagination-nav__sublabel">Older Post</div><div class="pagination-nav__label">How To Customise ShinyApp With Bootstrap, Javascript And Plotly</div></a></nav></main><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#step-summary" class="table-of-contents__link toc-highlight">Step Summary</a></li><li><a href="#steps" class="table-of-contents__link toc-highlight">Steps</a></li></ul></div></div></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/mydatahack-old-blog/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/takahirohonda" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 MDH.</div></div></div></footer></div>
</body>
</html>