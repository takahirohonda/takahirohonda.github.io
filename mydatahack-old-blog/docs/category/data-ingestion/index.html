<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.3.2">
<title data-rh="true">Data Ingestion | MyDatahack</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://mydatahack.com/docs/category/data-ingestion"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Data Ingestion | MyDatahack"><meta data-rh="true" name="description" content="Data Ingestion"><meta data-rh="true" property="og:description" content="Data Ingestion"><link data-rh="true" rel="icon" href="/img/icon-circle.png"><link data-rh="true" rel="canonical" href="https://mydatahack.com/docs/category/data-ingestion"><link data-rh="true" rel="alternate" href="https://mydatahack.com/docs/category/data-ingestion" hreflang="en"><link data-rh="true" rel="alternate" href="https://mydatahack.com/docs/category/data-ingestion" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="MyDatahack RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="MyDatahack Atom Feed">



<link rel="alternate" type="application/rss+xml" href="/web-technologies/rss.xml" title="MyDatahack RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/web-technologies/atom.xml" title="MyDatahack Atom Feed">
<link rel="alternate" type="application/rss+xml" href="/data-engineering/rss.xml" title="MyDatahack RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/data-engineering/atom.xml" title="MyDatahack Atom Feed">
<link rel="alternate" type="application/rss+xml" href="/data-science/rss.xml" title="MyDatahack RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/data-science/atom.xml" title="MyDatahack Atom Feed">
<link rel="alternate" type="application/rss+xml" href="/infrastructure/rss.xml" title="MyDatahack RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/infrastructure/atom.xml" title="MyDatahack Atom Feed"><link rel="stylesheet" href="/assets/css/styles.2668ea1a.css">
<script src="/assets/js/runtime~main.58181399.js" defer="defer"></script>
<script src="/assets/js/main.498d3b66.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/icon-circle.png" alt="MyDatahack Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/icon-circle.png" alt="MyDatahack Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">MyDatahack</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/">Blogs</a><a class="navbar__item navbar__link" href="/web-technologies">Web Technologies</a><a class="navbar__item navbar__link" href="/data-engineering">Data Engineering</a><a class="navbar__item navbar__link" href="/data-science">Data Science</a><a class="navbar__item navbar__link" href="/infrastructure">Infrastructure</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/takahirohonda" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/">index</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/category/etl">ETL</a><button aria-label="Expand sidebar category &#x27;ETL&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible menu__list-item-collapsible--active"><a class="menu__link menu__link--sublist menu__link--active" aria-current="page" href="/docs/category/data-ingestion">Data Ingestion</a><button aria-label="Collapse sidebar category &#x27;Data Ingestion&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/data-ingestion/s3-data-node-1">Event-Driven S3 Data Ingestion With Node.js Lambda Function and Deploy it with Serverless</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/data-ingestion/s3-data-ruby">Uploading and Downloading Files in S3 with Ruby</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/data-ingestion/s3-data-node-2">Uploading and Downloading Files in S3 with Node.js</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/data-ingestion/mongo-node-1">How to Ingest Data Into MongoDB with Node.js</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/data-ingestion/mong-node-2">How to Ingest Data From MongoDB with Node.js</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/data-ingestion/rest-api-node">REST API Data Ingestion with Node.js</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/data-ingestion/json-to-csv-to-pg-node">Converting JSON to CSV and Loading it to Postgres with Node.js</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/data-ingestion/csv-to-json-pg-node">Converting CSV to JSON and Loading it to Postgres with Node.js</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/data-ingestion/bulk-load-pg-node">Bulk Loading Postgres with Node.js</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/data-ingestion/json-with-python">A Comprehensive Guide for Reading and Writing JSON with Python</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/data-ingestion/fullstory-data-python">How to Ingest FullStory Data Export Extracts with Python</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/data-ingestion/jdbc-python">How to Bulk Load Data with JDBC and Python</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/data-ingestion/odbc-python">How to Bulk Load Data with ODBC and Python</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/data-ingestion/mysql-python">How to Bulk Load Data into MySQL with Python</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/data-ingestion/pg-python">How to Bulk Load Data into PostgreSQL with Python</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/data-ingestion/lambda-s3-rds-python">Event-Driven Data Ingestion with AWS Lambda (S3 to RDS)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/data-ingestion/lambda-s3-s3-python">Event-Driven Data Ingestion with AWS Lambda (S3 to S3)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/data-ingestion/s3-python">Comprehensive Guide to Download Files From S3 with Python</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/data-ingestion/pg-json">New JSON Data Ingestion Strategy by Using the Power of Postgres</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/data-ingestion/aes-encrypted-data-python">How To Ingest AES Encrypted Data With Python</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/data-ingestion/convert-non-utc-to-unix-python">How To Convert Non-UTC Timestamp Into UNIX Epoch Time In Python</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/data-ingestion/monog-python">How To Get Data From MongoDB With Python</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/data-ingestion/liveperson-data-r">How To Get Data From Liveperson And Create Aggregated Table With R</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/data-ingestion/liveperson-python">How To Ingest Data From Liveperson With Python</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/data-ingestion/sharepoint-python">How To Get Data From SharePoint With Python</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/data-ingestion/qualtrics-python">How To Get Survey Response Data From Qualtrics With Python</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/data-ingestion/s3-redshift-py">Data Engineering in S3 and Redshift with Python</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/data-ingestion/ga-py">How To Get Data From Google Analytics With Python</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/data-ingestion/facebook-py">How To Get Facebook Data With Python</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/data-ingestion/twitter-py">How To Get Twitter Data With Python</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/category/infrastructure">Infrastructure</a><button aria-label="Expand sidebar category &#x27;Infrastructure&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/category/web">Web</a><button aria-label="Expand sidebar category &#x27;Web&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/category/git">Git</a><button aria-label="Expand sidebar category &#x27;Git&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/category/chatgpt-generated">ChatGPT Generated</a><button aria-label="Expand sidebar category &#x27;ChatGPT Generated&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/doc-example/intro">doc-example</a></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="generatedIndexPage_vN6x"><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Data Ingestion</span><meta itemprop="position" content="1"></li></ul></nav><header><h1 class="title_kItE">Data Ingestion</h1><p>Data Ingestion</p></header><article class="margin-top--lg"><section class="row list_eTzJ"><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/docs/data-ingestion/s3-data-node-1"><h2 class="text--truncate cardTitle_rnsV" title="Event-Driven S3 Data Ingestion With Node.js Lambda Function and Deploy it with Serverless">üìÑÔ∏è<!-- --> <!-- -->Event-Driven S3 Data Ingestion With Node.js Lambda Function and Deploy it with Serverless</h2><p class="text--truncate cardDescription_PWke" title="Ingesting data upon the file creating on S3 bucket enables near real-time data ingestion. For example, you may need to ingest log files from applications or API monitoring tools as soon as they land on the bucket. Just to get it started, let‚Äôs move the file from the source bucket to the target as soon as it gets created in the source bucket by using the node.js lambda function.">Ingesting data upon the file creating on S3 bucket enables near real-time data ingestion. For example, you may need to ingest log files from applications or API monitoring tools as soon as they land on the bucket. Just to get it started, let‚Äôs move the file from the source bucket to the target as soon as it gets created in the source bucket by using the node.js lambda function.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/docs/data-ingestion/s3-data-ruby"><h2 class="text--truncate cardTitle_rnsV" title="Uploading and Downloading Files in S3 with Ruby">üìÑÔ∏è<!-- --> <!-- -->Uploading and Downloading Files in S3 with Ruby</h2><p class="text--truncate cardDescription_PWke" title="To date, the latest Ruby AWS SDK is version 3. In this version, each resources has its own module while the version 2 had the one with everything, aws-sdk. To interact with S3 with the v3 SDK, let‚Äôs use the aws-sdk-s3 module.">To date, the latest Ruby AWS SDK is version 3. In this version, each resources has its own module while the version 2 had the one with everything, aws-sdk. To interact with S3 with the v3 SDK, let‚Äôs use the aws-sdk-s3 module.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/docs/data-ingestion/s3-data-node-2"><h2 class="text--truncate cardTitle_rnsV" title="Uploading and Downloading Files in S3 with Node.js">üìÑÔ∏è<!-- --> <!-- -->Uploading and Downloading Files in S3 with Node.js</h2><p class="text--truncate cardDescription_PWke" title="AWS S3 is probably the most utilised AWS storage services. It is affordable, highly available, convenient and easy to use. To interact with any AWS services, Node.js requires AWS SDK for JavaScript.">AWS S3 is probably the most utilised AWS storage services. It is affordable, highly available, convenient and easy to use. To interact with any AWS services, Node.js requires AWS SDK for JavaScript.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/docs/data-ingestion/mongo-node-1"><h2 class="text--truncate cardTitle_rnsV" title="How to Ingest Data Into MongoDB with Node.js">üìÑÔ∏è<!-- --> <!-- -->How to Ingest Data Into MongoDB with Node.js</h2><p class="text--truncate cardDescription_PWke" title="Now that we got data from MongoDB and loaded into Postgres with some transformation, let‚Äôs put the data back into MongoDB. This post is the continuation of the previous post about ingesting data from MongoDB. You should totally start from How to Ingest Data From MongoDB with Node.js.">Now that we got data from MongoDB and loaded into Postgres with some transformation, let‚Äôs put the data back into MongoDB. This post is the continuation of the previous post about ingesting data from MongoDB. You should totally start from How to Ingest Data From MongoDB with Node.js.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/docs/data-ingestion/mong-node-2"><h2 class="text--truncate cardTitle_rnsV" title="How to Ingest Data From MongoDB with Node.js">üìÑÔ∏è<!-- --> <!-- -->How to Ingest Data From MongoDB with Node.js</h2><p class="text--truncate cardDescription_PWke" title="Data ingestion from a NoSQL database often involves the denormalisation of their schema-less data before loading into a relational database. In this post, we will try to grab the restaurant data from MongoDB, denormalise the collection into a parent and a child table, and load them into Postgres.">Data ingestion from a NoSQL database often involves the denormalisation of their schema-less data before loading into a relational database. In this post, we will try to grab the restaurant data from MongoDB, denormalise the collection into a parent and a child table, and load them into Postgres.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/docs/data-ingestion/rest-api-node"><h2 class="text--truncate cardTitle_rnsV" title="REST API Data Ingestion with Node.js">üìÑÔ∏è<!-- --> <!-- -->REST API Data Ingestion with Node.js</h2><p class="text--truncate cardDescription_PWke" title="The classic REST API data ingestion pattern is (1) to make an API call to the endpoint, (2) get the data, (3) transform it to a structured table and (4) load it to a database. Let‚Äôs have a go at it with Node.js. We are using JSONPlaceholder which offers a few different REST API endpoints for testing or experimenting. Let‚Äôs ingest the photos dataset into Postgres database.">The classic REST API data ingestion pattern is (1) to make an API call to the endpoint, (2) get the data, (3) transform it to a structured table and (4) load it to a database. Let‚Äôs have a go at it with Node.js. We are using JSONPlaceholder which offers a few different REST API endpoints for testing or experimenting. Let‚Äôs ingest the photos dataset into Postgres database.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/docs/data-ingestion/json-to-csv-to-pg-node"><h2 class="text--truncate cardTitle_rnsV" title="Converting JSON to CSV and Loading it to Postgres with Node.js">üìÑÔ∏è<!-- --> <!-- -->Converting JSON to CSV and Loading it to Postgres with Node.js</h2><p class="text--truncate cardDescription_PWke" title="To convert JSON to CSV, I love using json2csv. It really does all the hard work of working the JSON structure out and converting it to a flat file. For nested JSON elements, you can simply specify them by the dot notation (like transaction.itemId). When it contains an array element, it automatically expands it and creates a denormalised table for you. Well, let‚Äôs see how it works.">To convert JSON to CSV, I love using json2csv. It really does all the hard work of working the JSON structure out and converting it to a flat file. For nested JSON elements, you can simply specify them by the dot notation (like transaction.itemId). When it contains an array element, it automatically expands it and creates a denormalised table for you. Well, let‚Äôs see how it works.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/docs/data-ingestion/csv-to-json-pg-node"><h2 class="text--truncate cardTitle_rnsV" title="Converting CSV to JSON and Loading it to Postgres with Node.js">üìÑÔ∏è<!-- --> <!-- -->Converting CSV to JSON and Loading it to Postgres with Node.js</h2><p class="text--truncate cardDescription_PWke" title="To convert csv to json, Node has an awesome module, csvtojson. It takes a json file and convert it to csv asynchronously. Once we convert csv to json, let‚Äôs load it to a Postgres table with jsonb data type. Postgres supports JSON data and you can query it (see the previous blog about ingesting json into Postgres here). We are going to use pg-copy-streams to bulk load the json file into Postgres (see Bulk Loading Postgres with Node.js).">To convert csv to json, Node has an awesome module, csvtojson. It takes a json file and convert it to csv asynchronously. Once we convert csv to json, let‚Äôs load it to a Postgres table with jsonb data type. Postgres supports JSON data and you can query it (see the previous blog about ingesting json into Postgres here). We are going to use pg-copy-streams to bulk load the json file into Postgres (see Bulk Loading Postgres with Node.js).</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/docs/data-ingestion/bulk-load-pg-node"><h2 class="text--truncate cardTitle_rnsV" title="Bulk Loading Postgres with Node.js">üìÑÔ∏è<!-- --> <!-- -->Bulk Loading Postgres with Node.js</h2><p class="text--truncate cardDescription_PWke" title="The fastest way to bulk load data into Postgres is to call Copy, which is a SQL command to load data into a table from a flat file. To connect to Postgres with Node.js, we can use the node-postgres module (pg). To use the copy function, we can use the pg-copy-streams module, which enables you to execute the copy function from a file readable stream.">The fastest way to bulk load data into Postgres is to call Copy, which is a SQL command to load data into a table from a flat file. To connect to Postgres with Node.js, we can use the node-postgres module (pg). To use the copy function, we can use the pg-copy-streams module, which enables you to execute the copy function from a file readable stream.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/docs/data-ingestion/json-with-python"><h2 class="text--truncate cardTitle_rnsV" title="A Comprehensive Guide for Reading and Writing JSON with Python">üìÑÔ∏è<!-- --> <!-- -->A Comprehensive Guide for Reading and Writing JSON with Python</h2><p class="text--truncate cardDescription_PWke" title="A Comprehensive Guide for Reading and Writing JSON with Python">A Comprehensive Guide for Reading and Writing JSON with Python</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/docs/data-ingestion/fullstory-data-python"><h2 class="text--truncate cardTitle_rnsV" title="How to Ingest FullStory Data Export Extracts with Python">üìÑÔ∏è<!-- --> <!-- -->How to Ingest FullStory Data Export Extracts with Python</h2><p class="text--truncate cardDescription_PWke" title="If you are interested in user tracking on your website, FullStory is a pretty good option. You can sign up for the free version here. The free version includes heaps of cool features. When you first sign up, you can try all the Pro Edition features for 2 weeks, too.">If you are interested in user tracking on your website, FullStory is a pretty good option. You can sign up for the free version here. The free version includes heaps of cool features. When you first sign up, you can try all the Pro Edition features for 2 weeks, too.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/docs/data-ingestion/jdbc-python"><h2 class="text--truncate cardTitle_rnsV" title="How to Bulk Load Data with JDBC and Python">üìÑÔ∏è<!-- --> <!-- -->How to Bulk Load Data with JDBC and Python</h2><p class="text--truncate cardDescription_PWke" title="Let‚Äôs do data bulk load by using JDBC and Python. The aim of this post is pretty much the same as the previous one with ODBC. We are going to export a table into a csv file and import the exported file into a table by using JDBC drivers and Python. To interact with JDBC drivers, you need to install the JayDeBeApi module.">Let‚Äôs do data bulk load by using JDBC and Python. The aim of this post is pretty much the same as the previous one with ODBC. We are going to export a table into a csv file and import the exported file into a table by using JDBC drivers and Python. To interact with JDBC drivers, you need to install the JayDeBeApi module.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/docs/data-ingestion/odbc-python"><h2 class="text--truncate cardTitle_rnsV" title="How to Bulk Load Data with ODBC and Python">üìÑÔ∏è<!-- --> <!-- -->How to Bulk Load Data with ODBC and Python</h2><p class="text--truncate cardDescription_PWke" title="I think Hello World of Data Engineering to make an one-to-one copy of a table from the source to the target database by bulk-loading data. The fastest way to achieve this is exporting a table into a CSV file from the source database and importing a CSV file to a table in the target database. With any database, importing data from a flat file is faster than using insert or update statements.">I think Hello World of Data Engineering to make an one-to-one copy of a table from the source to the target database by bulk-loading data. The fastest way to achieve this is exporting a table into a CSV file from the source database and importing a CSV file to a table in the target database. With any database, importing data from a flat file is faster than using insert or update statements.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/docs/data-ingestion/mysql-python"><h2 class="text--truncate cardTitle_rnsV" title="How to Bulk Load Data into MySQL with Python">üìÑÔ∏è<!-- --> <!-- -->How to Bulk Load Data into MySQL with Python</h2><p class="text--truncate cardDescription_PWke" title="As in any other relational databases, the fastest way to load data into MySQL is to upload a flat file into a table. To do this, MySQL has a LOAD DATA INFILE function. We can use Python to execute this command. To connect to MySQL and execute SQL statements with Python, we will use the pymysql module.">As in any other relational databases, the fastest way to load data into MySQL is to upload a flat file into a table. To do this, MySQL has a LOAD DATA INFILE function. We can use Python to execute this command. To connect to MySQL and execute SQL statements with Python, we will use the pymysql module.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/docs/data-ingestion/pg-python"><h2 class="text--truncate cardTitle_rnsV" title="How to Bulk Load Data into PostgreSQL with Python">üìÑÔ∏è<!-- --> <!-- -->How to Bulk Load Data into PostgreSQL with Python</h2><p class="text--truncate cardDescription_PWke" title="Bulk loading with the copy command from a CSV file is the fastest option to load a large table with Postgres. In fact, loading data from a flat file is the fastest option in any relational databases. When you have a large table and need to load it to another database, the fastest way is to unload it to a flat file and upload it to the database table.">Bulk loading with the copy command from a CSV file is the fastest option to load a large table with Postgres. In fact, loading data from a flat file is the fastest option in any relational databases. When you have a large table and need to load it to another database, the fastest way is to unload it to a flat file and upload it to the database table.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/docs/data-ingestion/lambda-s3-rds-python"><h2 class="text--truncate cardTitle_rnsV" title="Event-Driven Data Ingestion with AWS Lambda (S3 to RDS)">üìÑÔ∏è<!-- --> <!-- -->Event-Driven Data Ingestion with AWS Lambda (S3 to RDS)</h2><p class="text--truncate cardDescription_PWke" title="In the previous post, we discussed how to move data from the source S3 bucket to the target whenever a new file is created in the source bucket by using AWS Lambda function. In this post, I will show you how to use Lambda to execute data ingestion from S3 to RDS whenever a new file is created in the source bucket. AWS Lambda supports a few different programming languages. We will use Python 3.6 here.">In the previous post, we discussed how to move data from the source S3 bucket to the target whenever a new file is created in the source bucket by using AWS Lambda function. In this post, I will show you how to use Lambda to execute data ingestion from S3 to RDS whenever a new file is created in the source bucket. AWS Lambda supports a few different programming languages. We will use Python 3.6 here.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/docs/data-ingestion/lambda-s3-s3-python"><h2 class="text--truncate cardTitle_rnsV" title="Event-Driven Data Ingestion with AWS Lambda (S3 to S3)">üìÑÔ∏è<!-- --> <!-- -->Event-Driven Data Ingestion with AWS Lambda (S3 to S3)</h2><p class="text--truncate cardDescription_PWke" title="Let‚Äôs say you have data coming into S3 in your AWS environment every 15 minutes and want to ingest it as it comes. The best approach for this near real-time ingestion is to use AWS lambda function. To demonstrate how to develop and deploy lambda function in AWS, we will have a look at a simple use case of moving file from source S3 to target S3 as the file is created in the source.">Let‚Äôs say you have data coming into S3 in your AWS environment every 15 minutes and want to ingest it as it comes. The best approach for this near real-time ingestion is to use AWS lambda function. To demonstrate how to develop and deploy lambda function in AWS, we will have a look at a simple use case of moving file from source S3 to target S3 as the file is created in the source.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/docs/data-ingestion/s3-python"><h2 class="text--truncate cardTitle_rnsV" title="Comprehensive Guide to Download Files From S3 with Python">üìÑÔ∏è<!-- --> <!-- -->Comprehensive Guide to Download Files From S3 with Python</h2><p class="text--truncate cardDescription_PWke" title="Using AWS SDK for Python can be confusing. First of all, there seems to be two different ones (Boto and Boto3). Even if you choose one, either one of them seems to have multiple ways to authenticate and connect to AWS services. Googling solutions can quickly become confusing as you may find different variations of code examples. If you are just getting into AWS, this can be scary. In this post, I will explain the different and give you the code examples that work by using the example of downloading files from S3.">Using AWS SDK for Python can be confusing. First of all, there seems to be two different ones (Boto and Boto3). Even if you choose one, either one of them seems to have multiple ways to authenticate and connect to AWS services. Googling solutions can quickly become confusing as you may find different variations of code examples. If you are just getting into AWS, this can be scary. In this post, I will explain the different and give you the code examples that work by using the example of downloading files from S3.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/docs/data-ingestion/pg-json"><h2 class="text--truncate cardTitle_rnsV" title="New JSON Data Ingestion Strategy by Using the Power of Postgres">üìÑÔ∏è<!-- --> <!-- -->New JSON Data Ingestion Strategy by Using the Power of Postgres</h2><p class="text--truncate cardDescription_PWke" title="Postgres always had a JSON support with somehow limited capability before the 9.2 version added the native JSON support. The release of version 9.3 has really taken the JSON feature to the next level with additional constructor and extractor methods. The capability of querying and transforming the JSON data type with Postgres gives you the new strategy to ingest JSON data from APIs or NoSQL databases.">Postgres always had a JSON support with somehow limited capability before the 9.2 version added the native JSON support. The release of version 9.3 has really taken the JSON feature to the next level with additional constructor and extractor methods. The capability of querying and transforming the JSON data type with Postgres gives you the new strategy to ingest JSON data from APIs or NoSQL databases.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/docs/data-ingestion/aes-encrypted-data-python"><h2 class="text--truncate cardTitle_rnsV" title="How To Ingest AES Encrypted Data With Python">üìÑÔ∏è<!-- --> <!-- -->How To Ingest AES Encrypted Data With Python</h2><p class="text--truncate cardDescription_PWke" title="To ingest encrypted data into DWH, we may ingest the data as it is or decrypt and load it to the database, depending on the business requirements. It is always good to know how to decrypt encrypted data. There are many encryption methods. Encryption usually happens at the application (either client or server) and encrypted data get passed to the database. It is up to your business requirements to ingest the encrypted data into DWH as it is or decrypt it before loading. There are also may ways to decrypt data in data ingestion process. SQL has its own decryption functions. You can decrypt it with ETL tools or programming language.">To ingest encrypted data into DWH, we may ingest the data as it is or decrypt and load it to the database, depending on the business requirements. It is always good to know how to decrypt encrypted data. There are many encryption methods. Encryption usually happens at the application (either client or server) and encrypted data get passed to the database. It is up to your business requirements to ingest the encrypted data into DWH as it is or decrypt it before loading. There are also may ways to decrypt data in data ingestion process. SQL has its own decryption functions. You can decrypt it with ETL tools or programming language.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/docs/data-ingestion/convert-non-utc-to-unix-python"><h2 class="text--truncate cardTitle_rnsV" title="How To Convert Non-UTC Timestamp Into UNIX Epoch Time In Python">üìÑÔ∏è<!-- --> <!-- -->How To Convert Non-UTC Timestamp Into UNIX Epoch Time In Python</h2><p class="text--truncate cardDescription_PWke" title="When we ingest API data, the query URI string often takes Unix epoch time (or Unix time) in order to specify the datetime range. The epoch time is the way to represent timestamp as the number of seconds that have elapsed since 1970-01-01 0000 UTC.">When we ingest API data, the query URI string often takes Unix epoch time (or Unix time) in order to specify the datetime range. The epoch time is the way to represent timestamp as the number of seconds that have elapsed since 1970-01-01 0000 UTC.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/docs/data-ingestion/monog-python"><h2 class="text--truncate cardTitle_rnsV" title="How To Get Data From MongoDB With Python">üìÑÔ∏è<!-- --> <!-- -->How To Get Data From MongoDB With Python</h2><p class="text--truncate cardDescription_PWke" title="How to get data from MongoDB with Python">How to get data from MongoDB with Python</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/docs/data-ingestion/liveperson-data-r"><h2 class="text--truncate cardTitle_rnsV" title="How To Get Data From Liveperson And Create Aggregated Table With R">üìÑÔ∏è<!-- --> <!-- -->How To Get Data From Liveperson And Create Aggregated Table With R</h2><p class="text--truncate cardDescription_PWke" title="In the previous post, we discussed how to ingest data from Liveperson with Python. In this post, I want to use R to make the same API call and create an aggregated table instead of preparing data for ingestion. The code is based on the example here. For further information on Liveperson API, you can have a look here.">In the previous post, we discussed how to ingest data from Liveperson with Python. In this post, I want to use R to make the same API call and create an aggregated table instead of preparing data for ingestion. The code is based on the example here. For further information on Liveperson API, you can have a look here.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/docs/data-ingestion/liveperson-python"><h2 class="text--truncate cardTitle_rnsV" title="How To Ingest Data From Liveperson With Python">üìÑÔ∏è<!-- --> <!-- -->How To Ingest Data From Liveperson With Python</h2><p class="text--truncate cardDescription_PWke" title="Engagment History API let you grab livechat interaction data from Liveperson. It is based on the REST architecture and uses OAuth1.0. You first need to retrieve API Keys. In this example, I am using the requests and requests_oauthlib modules to make API calls from Python. Liveperson offers a good code examples and this is a good place to start.">Engagment History API let you grab livechat interaction data from Liveperson. It is based on the REST architecture and uses OAuth1.0. You first need to retrieve API Keys. In this example, I am using the requests and requests_oauthlib modules to make API calls from Python. Liveperson offers a good code examples and this is a good place to start.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/docs/data-ingestion/sharepoint-python"><h2 class="text--truncate cardTitle_rnsV" title="How To Get Data From SharePoint With Python">üìÑÔ∏è<!-- --> <!-- -->How To Get Data From SharePoint With Python</h2><p class="text--truncate cardDescription_PWke" title="It‚Äôs sometimes convenient to have a script to get data from SharePoint. We can automate the user managed data ingesting from SharePoint. For example, business users can upload or update the user managed file and a scheduled ETL task fetch and bring it to the datalake.">It‚Äôs sometimes convenient to have a script to get data from SharePoint. We can automate the user managed data ingesting from SharePoint. For example, business users can upload or update the user managed file and a scheduled ETL task fetch and bring it to the datalake.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/docs/data-ingestion/qualtrics-python"><h2 class="text--truncate cardTitle_rnsV" title="How To Get Survey Response Data From Qualtrics With Python">üìÑÔ∏è<!-- --> <!-- -->How To Get Survey Response Data From Qualtrics With Python</h2><p class="text--truncate cardDescription_PWke" title="In the previous post, we had a look at Python code examples of basic data engineering with AWS infrastructure. By using Qualtrics API, I would like to present a coding example of API data ingestion into S3 and Redshift. This code can be scheduled hourly, daily or weekly in a server or AWS Data Pipeline.">In the previous post, we had a look at Python code examples of basic data engineering with AWS infrastructure. By using Qualtrics API, I would like to present a coding example of API data ingestion into S3 and Redshift. This code can be scheduled hourly, daily or weekly in a server or AWS Data Pipeline.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/docs/data-ingestion/s3-redshift-py"><h2 class="text--truncate cardTitle_rnsV" title="Data Engineering in S3 and Redshift with Python">üìÑÔ∏è<!-- --> <!-- -->Data Engineering in S3 and Redshift with Python</h2><p class="text--truncate cardDescription_PWke" title="AWS offers a nice solution to data warehousing with their columnar database, Redshift, and an object storage, S3. Python and AWS SDK make it easy for us to move data in the ecosystem.">AWS offers a nice solution to data warehousing with their columnar database, Redshift, and an object storage, S3. Python and AWS SDK make it easy for us to move data in the ecosystem.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/docs/data-ingestion/ga-py"><h2 class="text--truncate cardTitle_rnsV" title="How To Get Data From Google Analytics With Python">üìÑÔ∏è<!-- --> <!-- -->How To Get Data From Google Analytics With Python</h2><p class="text--truncate cardDescription_PWke" title="When you ingest data from Google Analytics, you need to create a series of reports based on GA dimensions and metrics. The granularity is determined by dimensions you add in the report. The most important thing is to understand business requirements before start ingesting data. Good requirement analysis will enable you to drill up and down metrics at the right granularity and slice them with the dimensions that are critical to the business.">When you ingest data from Google Analytics, you need to create a series of reports based on GA dimensions and metrics. The granularity is determined by dimensions you add in the report. The most important thing is to understand business requirements before start ingesting data. Good requirement analysis will enable you to drill up and down metrics at the right granularity and slice them with the dimensions that are critical to the business.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/docs/data-ingestion/facebook-py"><h2 class="text--truncate cardTitle_rnsV" title="How To Get Facebook Data With Python">üìÑÔ∏è<!-- --> <!-- -->How To Get Facebook Data With Python</h2><p class="text--truncate cardDescription_PWke" title="By using Facebook Graph API, we can get the feed of posts and links published by the specific page, or by others on this page as well as likes and comments (feed api). I have written a python script to scrape the feed info in the JSON format and turn it into structured tables. Once the data is in the tabular format, we can load it in the relational database or use common analytical tools (like Excel) to do further analysis.">By using Facebook Graph API, we can get the feed of posts and links published by the specific page, or by others on this page as well as likes and comments (feed api). I have written a python script to scrape the feed info in the JSON format and turn it into structured tables. Once the data is in the tabular format, we can load it in the relational database or use common analytical tools (like Excel) to do further analysis.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/docs/data-ingestion/twitter-py"><h2 class="text--truncate cardTitle_rnsV" title="How To Get Twitter Data With Python">üìÑÔ∏è<!-- --> <!-- -->How To Get Twitter Data With Python</h2><p class="text--truncate cardDescription_PWke" title="In this post, we will discuss how to use Python to grab publicly available Twitter post data (from any user you specify) and convert it into a tabular format so that we can analyse the data through Excel or insert them into a relational database. Python has a package that is a wrapper around the Twitter API (python-twitter). The package is easy to use and works fine. In this post, I used the generic requests package to make API calls to the endpoint for timeline.">In this post, we will discuss how to use Python to grab publicly available Twitter post data (from any user you specify) and convert it into a tabular format so that we can analyse the data through Excel or insert them into a relational database. Python has a package that is a wrapper around the Twitter API (python-twitter). The package is easy to use and works fine. In this post, I used the generic requests package to make API calls to the endpoint for timeline.</p></a></article></section></article><footer class="margin-top--lg"><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/ETL/Talend/uploading-csv"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Tips and Troubleshooting For Uploading CSV to Database In Talend</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/data-ingestion/s3-data-node-1"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Event-Driven S3 Data Ingestion With Node.js Lambda Function and Deploy it with Serverless</div></a></nav></footer></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/takahirohonda" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright ¬© 2024 MDH.</div></div></div></footer></div>
</body>
</html>